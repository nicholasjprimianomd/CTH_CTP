{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pydicom\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicom_directory = 'D:\\\\CTH_archive\\\\DICOM'\n",
    "all_files_metadata = []\n",
    "\n",
    "# Dictionaries to track patient files\n",
    "patients_colored_files = {}  # PatientID -> List of 'viz tmax colored' file paths\n",
    "patients_tmax_files = {}     # PatientID -> List of 'viz tmax' file paths\n",
    "\n",
    "total_files = sum([len(files) for r, d, files in os.walk(dicom_directory) if any(file.endswith('.dcm') for file in files)])\n",
    "\n",
    "with tqdm(total=total_files, desc=\"Processing DICOM Files\") as pbar:\n",
    "    for root, dirs, files in os.walk(dicom_directory):\n",
    "        for file in files:\n",
    "            if file.endswith('.dcm'):\n",
    "                file_path = os.path.join(root, file)\n",
    "                try:\n",
    "                    dicom = pydicom.dcmread(file_path, stop_before_pixels=True)\n",
    "                    metadata = {tag: getattr(dicom, tag, '') for tag in dicom.dir()}\n",
    "                    metadata['FilePath'] = file_path\n",
    "                    all_files_metadata.append(metadata)\n",
    "\n",
    "                    metadata_str_lower = {k: str(v).lower() for k, v in metadata.items()}\n",
    "                    metadata_combined_str = ' '.join(metadata_str_lower.values())\n",
    "\n",
    "                    patient_id = metadata.get('PatientID')\n",
    "                    if \"viz tmax colored\" in metadata_combined_str:\n",
    "                        patients_colored_files.setdefault(patient_id, []).append(file_path)\n",
    "                    elif \"viz tmax\" in metadata_combined_str:\n",
    "                        patients_tmax_files.setdefault(patient_id, []).append(file_path)\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Error reading {file_path}: {e}\")\n",
    "                pbar.update(1)\n",
    "\n",
    "# Determine final file list, prioritizing 'viz tmax colored'\n",
    "matching_files = []\n",
    "for patient_id, file_paths in patients_colored_files.items():\n",
    "    matching_files.extend(file_paths)\n",
    "\n",
    "for patient_id, file_paths in patients_tmax_files.items():\n",
    "    if patient_id not in patients_colored_files:\n",
    "        matching_files.extend(file_paths)\n",
    "\n",
    "# Print or process the matching files\n",
    "for file in matching_files:\n",
    "    print(f\"Matching file: {file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_unique_mrn(file_paths):\n",
    "    \"\"\"\n",
    "    Count unique MRNs in a list of DICOM file paths.\n",
    "\n",
    "    :param file_paths: List of file paths.\n",
    "    :return: The count of unique MRNs.\n",
    "    \"\"\"\n",
    "    unique_mrns = set()\n",
    "\n",
    "    for path in file_paths:\n",
    "        # Split the path and extract the MRN segment\n",
    "        parts = path.split(os.sep)\n",
    "\n",
    "        mrn = parts[3]\n",
    "        unique_mrns.add(mrn)\n",
    "            \n",
    "\n",
    "    return len(unique_mrns)\n",
    "\n",
    "\n",
    "unique_mrn_count = count_unique_mrn(matching_files)\n",
    "print(f\"Unique MRN count: {unique_mrn_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_unique_mrn(file_paths):\n",
    "    \"\"\"\n",
    "    Count unique MRNs in a list of DICOM file paths.\n",
    "\n",
    "    :param file_paths: List of file paths.\n",
    "    :return: The count of unique MRNs.\n",
    "    \"\"\"\n",
    "    unique_mrns = set()\n",
    "\n",
    "    for path in file_paths:\n",
    "        # Split the path and extract the MRN segment\n",
    "        parts = path.split(os.sep)\n",
    "\n",
    "        mrn = parts[3]\n",
    "        unique_mrns.add(mrn)\n",
    "            \n",
    "\n",
    "    return unique_mrns\n",
    "\n",
    "\n",
    "mrn_list = list_unique_mrn(matching_files)\n",
    "print(f\"Unique MRN count: {mrn_list}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('CTP.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    for path in matching_files:\n",
    "        writer.writerow([path]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pydicom\n",
    "from tqdm import tqdm\n",
    "search_terms = {\"Head  5.0  J45s  1\", \"AXIAL\", \"AXIAL (Stroke Alert)\", \"Head  5.0  MPR  ax\", \n",
    "    \"AXIAL STND\", \"Axial Head 5.0\", \"Soft\", \"Brain Brain\", \n",
    "    \"ROUTINE HEAD\", \"AX SOFT\", \"AX5ST.\"}\n",
    "\n",
    "\n",
    "def search_dicom_files(directory, terms):\n",
    "    matching_files = []\n",
    "\n",
    "    # Create a list of all DICOM files\n",
    "    dicom_files = [os.path.join(root, file) for root, dirs, files in os.walk(directory) \n",
    "                   for file in files if file.endswith(\".dcm\")]\n",
    "\n",
    "\n",
    "    for file_path in tqdm(dicom_files, desc=\"Processing DICOM files\"):\n",
    "        try:\n",
    "            dicom_file = pydicom.dcmread(file_path)\n",
    "            if any(term in dicom_file.SeriesDescription for term in terms):\n",
    "                matching_files.append(file_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading file {file_path}: {e}\")\n",
    "\n",
    "    return matching_files\n",
    "\n",
    "\n",
    "matching_file_paths = search_dicom_files(\"D:\\\\CTH_archive\\\\DICOM\", search_terms)\n",
    "print(matching_file_paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pydicom\n",
    "from tqdm import tqdm\n",
    "search_terms = {\"VPCT Perfusion 5.0 H20f, CTP, CT PERFUSION, CTP 5.0 Hr38\"}\n",
    "\n",
    "\n",
    "def search_dicom_files(directory, terms):\n",
    "    matching_files = []\n",
    "\n",
    "    # Create a list of all DICOM files\n",
    "    dicom_files = [os.path.join(root, file) for root, dirs, files in os.walk(directory) \n",
    "                   for file in files if file.endswith(\".dcm\")]\n",
    "\n",
    "\n",
    "    for file_path in tqdm(dicom_files, desc=\"Processing DICOM files\"):\n",
    "        try:\n",
    "            dicom_file = pydicom.dcmread(file_path)\n",
    "            if any(term in dicom_file.SeriesDescription for term in terms):\n",
    "                matching_files.append(file_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading file {file_path}: {e}\")\n",
    "\n",
    "    return matching_files\n",
    "\n",
    "\n",
    "matching_file_paths = search_dicom_files(\"D:\\\\CTH_archive\\\\DICOM\", search_terms)\n",
    "print(matching_file_paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('CTH.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    for path in matching_file_paths:\n",
    "        writer.writerow([path]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_mrn_count = count_unique_mrn(matching_file_paths )\n",
    "mathcing_files_list =  list_unique_mrn(matching_file_paths)\n",
    "print(f\"Unique MRN count: {unique_mrn_count}\")\n",
    "print(f\"mathcing_files_list: {mathcing_files_list}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('CTP.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    for item in mathcing_files_list:\n",
    "        name, number = item.rsplit(' ', 1)  # Split each item into name and number\n",
    "        writer.writerow([name, number]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mathcing_files_list ^ set(os.listdir(\"D:\\\\CTH_archive\\\\DICOM\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Directory containing DICOM files\n",
    "dicom_dir = r\"D:\\CTH_archive\\DICOM\\KUHNER_ROSEMARY 4716150\\2020-09-11 214748\"\n",
    "\n",
    "# List to hold DICOM descriptions\n",
    "dicom_descriptions = []\n",
    "\n",
    "# Loop through all files in the directory\n",
    "for filename in os.listdir(dicom_dir):\n",
    "    if filename.endswith(\".dcm\"):\n",
    "        filepath = os.path.join(dicom_dir, filename)\n",
    "        ds = pydicom.dcmread(filepath)\n",
    "        \n",
    "        # Extract description and add it to the list\n",
    "        description = ds.get(\"SeriesDescription\", \"No description available\")\n",
    "        dicom_descriptions.append(description)\n",
    "\n",
    "# Print out all descriptions\n",
    "for desc in dicom_descriptions:\n",
    "    print(desc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = r'D:\\CTH_archive\\DICOM\\KUHNER_ROSEMARY 4716150\\2020-09-11 214748'\n",
    "rows_list = []\n",
    "columns_list = []\n",
    "\n",
    "for file in os.listdir(folder_path):\n",
    "    if file.endswith(\".dcm\"):  # Checking for DICOM files\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        dicom_data = pydicom.dcmread(file_path)\n",
    "\n",
    "        # Extracting rows and columns\n",
    "        rows = dicom_data.Rows\n",
    "        columns = dicom_data.Columns\n",
    "\n",
    "        rows_list.append(rows)\n",
    "        columns_list.append(columns)\n",
    "\n",
    "# Plotting histograms\n",
    "if rows_list and columns_list:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Histogram for Rows\n",
    "    plt.subplot(1, 2, 1)  # 1 row, 2 columns, 1st subplot\n",
    "    plt.hist(rows_list, bins=10, color='blue', edgecolor='black')\n",
    "    plt.title('Histogram of DICOM Image Rows')\n",
    "    plt.xlabel('Rows')\n",
    "    plt.ylabel('Frequency')\n",
    "\n",
    "    # Histogram for Columns\n",
    "    plt.subplot(1, 2, 2)  # 1 row, 2 columns, 2nd subplot\n",
    "    plt.hist(columns_list, bins=10, color='green', edgecolor='black')\n",
    "    plt.title('Histogram of DICOM Image Columns')\n",
    "    plt.xlabel('Columns')\n",
    "    plt.ylabel('Frequency')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No DICOM files found in the specified folder.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = r'D:\\CTH_archive\\DICOM\\KUHNER_ROSEMARY 4716150\\2020-09-11 220939'\n",
    "rows_list = []\n",
    "columns_list = []\n",
    "\n",
    "for file in os.listdir(folder_path):\n",
    "    if file.endswith(\".dcm\"):  # Checking for DICOM files\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        dicom_data = pydicom.dcmread(file_path)\n",
    "\n",
    "        # Extracting rows and columns\n",
    "        rows = dicom_data.Rows\n",
    "        columns = dicom_data.Columns\n",
    "\n",
    "        rows_list.append(rows)\n",
    "        columns_list.append(columns)\n",
    "\n",
    "# Plotting histograms\n",
    "if rows_list and columns_list:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Histogram for Rows\n",
    "    plt.subplot(1, 2, 1)  # 1 row, 2 columns, 1st subplot\n",
    "    plt.hist(rows_list, bins=10, color='blue', edgecolor='black')\n",
    "    plt.title('Histogram of DICOM Image Rows')\n",
    "    plt.xlabel('Rows')\n",
    "    plt.ylabel('Frequency')\n",
    "\n",
    "    # Histogram for Columns\n",
    "    plt.subplot(1, 2, 2)  # 1 row, 2 columns, 2nd subplot\n",
    "    plt.hist(columns_list, bins=10, color='green', edgecolor='black')\n",
    "    plt.title('Histogram of DICOM Image Columns')\n",
    "    plt.xlabel('Columns')\n",
    "    plt.ylabel('Frequency')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No DICOM files found in the specified folder.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import pydicom\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Base directory for the DICOM files and the new cropped folder\n",
    "base_directory = r'D:\\CTH_archive'\n",
    "dicom_directory = os.path.join(base_directory, 'DICOM')\n",
    "cropped_directory = os.path.join(base_directory, 'cropped')\n",
    "\n",
    "# Path to the CSV file\n",
    "csv_file_path = r'C:\\Users\\nprim\\Desktop\\CTP.csv'\n",
    "\n",
    "# Define the cropping coordinates\n",
    "x1, y1, x2, y2 = 50, 35, 235, 235  # The rectangle coordinates\n",
    "\n",
    "# Read the file paths from the CSV\n",
    "dicom_file_paths = []\n",
    "with open(csv_file_path, mode='r', newline='', encoding='utf-8-sig') as file:\n",
    "    reader = csv.reader(file)\n",
    "    for row in reader:\n",
    "        dicom_file_paths.extend(row)  # Assuming each row contains one file path\n",
    "\n",
    "# Process each DICOM file\n",
    "for file_path in dicom_file_paths:\n",
    "    try:\n",
    "        # Read the DICOM file\n",
    "        dicom_data = pydicom.dcmread(file_path)\n",
    "        image_array = dicom_data.pixel_array\n",
    "\n",
    "        # Convert to a format that PIL can understand\n",
    "        if len(image_array.shape) == 2:  # Grayscale\n",
    "            image = Image.fromarray(image_array).convert('L')\n",
    "        elif len(image_array.shape) == 3:  # RGB\n",
    "            image = Image.fromarray(image_array)\n",
    "\n",
    "        # Convert to JPG\n",
    "        jpg_file_path = file_path.replace('.dcm', '.jpg')\n",
    "        image.save(jpg_file_path)\n",
    "\n",
    "        # Open the JPG image and crop it\n",
    "        jpg_image = Image.open(jpg_file_path)\n",
    "        cropped_image = jpg_image.crop((x1, y1, x2, y2))\n",
    "\n",
    "        # Replicate the folder structure in the cropped directory\n",
    "        relative_path = os.path.relpath(jpg_file_path, dicom_directory)\n",
    "        cropped_file_path = os.path.join(cropped_directory, relative_path)\n",
    "        os.makedirs(os.path.dirname(cropped_file_path), exist_ok=True)\n",
    "\n",
    "        # Save the cropped image\n",
    "        cropped_image.save(cropped_file_path)\n",
    "\n",
    "        print(f\"Cropped image saved to {cropped_file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base directory where .dcm files need to be deleted\n",
    "base_directory = r'D:\\CTH_archive\\cropped'\n",
    "\n",
    "# Recursively find all .dcm files\n",
    "dcm_files = glob.glob(os.path.join(base_directory, '**', '*.dcm'), recursive=True)\n",
    "\n",
    "# Delete each found .dcm file\n",
    "for file_path in dcm_files:\n",
    "    try:\n",
    "        os.remove(file_path)\n",
    "        print(f\"Deleted file: {file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error deleting {file_path}: {e}\")\n",
    "\n",
    "print(\"Deletion of .dcm files complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def apply_modality_lut(image_array, dicom_data):\n",
    "    \"\"\"\n",
    "    Apply Modality LUT (Rescale Slope and Intercept).\n",
    "    \"\"\"\n",
    "    rescale_slope = dicom_data.RescaleSlope if 'RescaleSlope' in dicom_data else 1\n",
    "    rescale_intercept = dicom_data.RescaleIntercept if 'RescaleIntercept' in dicom_data else 0\n",
    "    return image_array * rescale_slope + rescale_intercept\n",
    "\n",
    "def apply_windowing(image_array, window_center, window_width):\n",
    "    \"\"\"\n",
    "    Apply windowing to the DICOM image array.\n",
    "    \"\"\"\n",
    "    img_min = window_center - window_width // 2\n",
    "    img_max = window_center + window_width // 2\n",
    "    windowed_image = np.clip(image_array, img_min, img_max)\n",
    "    windowed_image = ((windowed_image - img_min) / (img_max - img_min)) * 255.0\n",
    "    return windowed_image.astype(np.uint8)\n",
    "\n",
    "# Paths\n",
    "csv_file_path = r'C:\\Users\\nprim\\Desktop\\CTH.csv'\n",
    "base_directory = r'D:\\CTH_archive\\DICOM'\n",
    "target_directory = r'D:\\CTH_archive\\CTH_JPG'\n",
    "\n",
    "# Read file paths from CSV\n",
    "file_paths = []\n",
    "with open(csv_file_path, mode='r', newline='', encoding='utf-8-sig') as file:\n",
    "    reader = csv.reader(file)\n",
    "    for row in reader:\n",
    "        file_paths.extend(row)\n",
    "\n",
    "# Process each file\n",
    "for file_path in file_paths:\n",
    "    try:\n",
    "        # Read DICOM file\n",
    "        dicom_data = pydicom.dcmread(file_path)\n",
    "        image_array = apply_modality_lut(dicom_data.pixel_array, dicom_data)\n",
    "\n",
    "        # Apply windowing (adjust these values as needed)\n",
    "        #window_center, window_width = 40, 80  # Example values; adjust based on your DICOM data\n",
    "        #if 'WindowCenter' in dicom_data and 'WindowWidth' in dicom_data:\n",
    "        #    window_center, window_width = int(dicom_data.WindowCenter), int(dicom_data.WindowWidth)\n",
    "\n",
    "            # Handling WindowCenter and WindowWidth\n",
    "        if 'WindowCenter' in dicom_data and 'WindowWidth' in dicom_data:\n",
    "            window_center = dicom_data.WindowCenter\n",
    "            window_width = dicom_data.WindowWidth\n",
    "\n",
    "        # Check if WindowCenter or WindowWidth is a MultiValue and handle accordingly\n",
    "        if isinstance(window_center, pydicom.multival.MultiValue):\n",
    "            window_center = int(window_center[0])  # Taking the first value as an example\n",
    "        else:\n",
    "            window_center = int(window_center)\n",
    "        if isinstance(window_width, pydicom.multival.MultiValue):\n",
    "            window_width = int(window_width[0])  # Taking the first value as an example\n",
    "        else:\n",
    "            window_width = int(window_width)\n",
    "\n",
    "\n",
    "\n",
    "        image_array = apply_windowing(image_array, window_center, window_width)\n",
    "\n",
    "        # Convert to image and save as JPG\n",
    "        image = Image.fromarray(image_array).convert('L')  # Convert to grayscale\n",
    "        relative_path = os.path.relpath(file_path, base_directory)\n",
    "        new_path = os.path.join(target_directory, relative_path)\n",
    "        new_path = new_path.replace('.dcm', '.jpg')  # Change extension to .jpg\n",
    "        os.makedirs(os.path.dirname(new_path), exist_ok=True)\n",
    "        image.save(new_path, 'JPEG')\n",
    "        print(f\"Saved JPG file at {new_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def convert_jpg_to_nifti(jpg_dir, output_dir):\n",
    "    for subdir, dirs, files in os.walk(jpg_dir):\n",
    "        # Filter and sort JPG files\n",
    "        jpg_files = sorted([f for f in files if f.endswith('.jpg')])\n",
    "\n",
    "        # Skip directories without JPG files\n",
    "        if not jpg_files:\n",
    "            continue\n",
    "\n",
    "        # Initialize an empty list to hold image data\n",
    "        image_data = []\n",
    "\n",
    "        # Read each image and append to the list\n",
    "        for file in jpg_files:\n",
    "            img_path = os.path.join(subdir, file)\n",
    "            img = Image.open(img_path).convert('L')  # convert to grayscale if needed\n",
    "            img_array = np.array(img)\n",
    "            image_data.append(img_array)\n",
    "\n",
    "        # Stack images into a 3D array\n",
    "        image_3d = np.stack(image_data, axis=-1)\n",
    "\n",
    "        # Create a NIfTI image (Assuming no header info, default affine)\n",
    "        nifti_img = nib.Nifti1Image(image_3d, affine=np.eye(4))\n",
    "\n",
    "        # Construct output file path\n",
    "        subdir_name = os.path.basename(subdir)\n",
    "        output_file = os.path.join(output_dir, subdir_name + '.nii')\n",
    "\n",
    "        # Save the NIfTI image\n",
    "        nib.save(nifti_img, output_file)\n",
    "        print(f\"Saved NIfTI image for {subdir_name}\")\n",
    "\n",
    "# Example usage\n",
    "convert_jpg_to_nifti(r'D:\\CTH_archive\\CTP_CROPPED_JPG', r'D:\\CTH_archive\\CTP_NFTI')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def convert_jpg_to_nifti(jpg_dir, output_dir):\n",
    "    for subdir, dirs, files in os.walk(jpg_dir):\n",
    "        jpg_files = sorted([f for f in files if f.endswith('.jpg')])\n",
    "        if not jpg_files:\n",
    "            continue\n",
    "\n",
    "        image_data = []\n",
    "        for file in jpg_files:\n",
    "            img_path = os.path.join(subdir, file)\n",
    "            img = Image.open(img_path).convert('L')\n",
    "            img_array = np.array(img)\n",
    "            image_data.append(img_array)\n",
    "\n",
    "        if not image_data:\n",
    "            continue\n",
    "\n",
    "        image_3d = np.stack(image_data, axis=-1)\n",
    "\n",
    "        # Calculate relative path from jpg_dir and replace spaces with underscores\n",
    "        relative_subdir = os.path.relpath(subdir, jpg_dir)\n",
    "        relative_subdir = relative_subdir.replace(' ', '_')\n",
    "        \n",
    "        # Create output subdirectory path\n",
    "        output_subdir = os.path.join(output_dir, relative_subdir)\n",
    "        os.makedirs(output_subdir, exist_ok=True)\n",
    "\n",
    "        # Construct output file path\n",
    "        output_file_name = f'{os.path.basename(relative_subdir)}.nii'\n",
    "        output_file = os.path.join(output_subdir, output_file_name)\n",
    "\n",
    "        # Save the NIfTI image\n",
    "        nifti_img = nib.Nifti1Image(image_3d, affine=np.eye(4))\n",
    "        nib.save(nifti_img, output_file)\n",
    "        print(f\"Saved NIfTI image at {output_file}\")\n",
    "\n",
    "# Example usage\n",
    "convert_jpg_to_nifti(r'D:\\CTH_archive\\CTP_CROPPED_JPG', r'D:\\CTH_archive\\CTP_NFTI')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
