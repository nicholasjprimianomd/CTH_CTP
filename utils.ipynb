{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "from totalsegmentator.python_api import totalsegmentator\n",
    "import os\n",
    "import SimpleITK as sitk\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from image_utils import convert_series_to_nifti, quantize_maps\n",
    "%matplotlib widget\n",
    "import gui\n",
    "import registration_gui as rgui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define directories\n",
    "input_folder = r'D:\\CTH_archive\\CTH_NIFTI'\n",
    "stripped_folder = r'D:\\CTH_archive\\CTH_STRIPPED_MASK'\n",
    "output_folder = r'D:\\CTH_archive\\CTH_STRIPPED'\n",
    "\n",
    "# Ensure the stripped and output directories exist\n",
    "os.makedirs(stripped_folder, exist_ok=True)\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Skull stripping process\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.endswith(('.nii')):\n",
    "        patient_name = filename.split(' ')[0]  # Extract patient name\n",
    "        input_path = os.path.join(input_folder, filename)\n",
    "        stripped_path = os.path.join(stripped_folder, patient_name)\n",
    "\n",
    "        # Check if the stripped file already exists\n",
    "        if not os.path.exists(stripped_path):\n",
    "            try:\n",
    "                input_img = nib.load(input_path)\n",
    "                totalsegmentator(input_img, stripped_path, roi_subset=['brain'], ml=True)\n",
    "                print(f\"Processed and saved: {stripped_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {input_path}: {e}\")\n",
    "        else:\n",
    "            print(f\"Stripped file already exists, skipping: {stripped_path}\")\n",
    "\n",
    "# Applying masks to stripped images\n",
    "file_counter = 0  # Initialize file counter\n",
    "missing_files = []\n",
    "\n",
    "for mask_filename in tqdm(os.listdir(stripped_folder)):\n",
    "    base_filename = os.path.splitext(mask_filename)[0].rsplit('.', 1)[0]  # Handle potential double extensions\n",
    "    original_path = None\n",
    "\n",
    "    # Find matching original file\n",
    "    for original_filename in os.listdir(input_folder):\n",
    "        if os.path.splitext(original_filename)[0].rsplit('.', 1)[0] == base_filename:\n",
    "            original_path = os.path.join(input_folder, original_filename)\n",
    "            break\n",
    "\n",
    "    if original_path:\n",
    "        mask_path = os.path.join(stripped_folder, mask_filename)\n",
    "        #output_filename = base_filename + f\"_{file_counter:03d}_0000.nii.gz\"\n",
    "        output_filename = base_filename\n",
    "        output_path = os.path.join(output_folder, output_filename)\n",
    "\n",
    "        # Check if the output file already exists\n",
    "        if not os.path.exists(output_path):\n",
    "            print(f\"Applying mask to {original_path} using {mask_path}\")\n",
    "\n",
    "            # Load and apply mask\n",
    "            mask_nii = nib.load(mask_path)\n",
    "            original_nii = nib.load(original_path)\n",
    "            masked_data = np.where(mask_nii.get_fdata() > 0, original_nii.get_fdata(), 0)\n",
    "            masked_nii = nib.Nifti1Image(masked_data, affine=original_nii.affine)\n",
    "\n",
    "            nib.save(masked_nii, output_path)\n",
    "            file_counter += 1\n",
    "        else:\n",
    "            print(f\"Masked file already exists, skipping: {output_path}\")\n",
    "    else:\n",
    "        print(f\"No matching file found for {mask_filename} in {input_folder}\")\n",
    "        missing_files.append((mask_filename, input_folder))\n",
    "\n",
    "print(\"Mask application complete.\")\n",
    "if missing_files:\n",
    "    print(\"Missing files:\", missing_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TMAX_SOURCE_DIR = r'D:\\\\CTH_archive\\\\TMAX_NIFTI\\\\'\n",
    "TMAX_QUNTIZED_DIR = r'D:\\\\CTH_archive\\\\TMAX_NIFTI_QUANT'\n",
    "\n",
    "quantization_levels = 5\n",
    "\n",
    "quantize_maps(TMAX_SOURCE_DIR, TMAX_QUNTIZED_DIR, quantization_levels=quantization_levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10b5a2accaae40a8a019cfa591af173e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final metric value: -0.24667615149076697\n",
      "Optimizer's stopping condition, GradientDescentLineSearchOptimizerv4Template: Convergence checker passed at iteration 20.\n",
      "Registration successful for patient: ALFORD_BARBARA. Transform saved to D:/CTH_archive/TRANSFORMS_STRIPPED\\ALFORD_BARBARA.h5\n",
      "Final metric value: -0.32760509814290395\n",
      "Optimizer's stopping condition, GradientDescentLineSearchOptimizerv4Template: Convergence checker passed at iteration 28.\n",
      "Registration successful for patient: ALLAH_MAJUSTICE. Transform saved to D:/CTH_archive/TRANSFORMS_STRIPPED\\ALLAH_MAJUSTICE.h5\n",
      "Final metric value: -0.19979278403478723\n",
      "Optimizer's stopping condition, GradientDescentLineSearchOptimizerv4Template: Convergence checker passed at iteration 68.\n",
      "Registration successful for patient: BATTLE_MARIA. Transform saved to D:/CTH_archive/TRANSFORMS_STRIPPED\\BATTLE_MARIA.h5\n",
      "Final metric value: -0.36338214178141753\n",
      "Optimizer's stopping condition, GradientDescentLineSearchOptimizerv4Template: Convergence checker passed at iteration 17.\n",
      "Registration successful for patient: BAUM_ROBERT. Transform saved to D:/CTH_archive/TRANSFORMS_STRIPPED\\BAUM_ROBERT.h5\n",
      "Final metric value: -0.3459314282092038\n",
      "Optimizer's stopping condition, GradientDescentLineSearchOptimizerv4Template: Convergence checker passed at iteration 29.\n",
      "Registration successful for patient: BILLIPS_JAMES. Transform saved to D:/CTH_archive/TRANSFORMS_STRIPPED\\BILLIPS_JAMES.h5\n",
      "Final metric value: -0.270177611646127\n",
      "Optimizer's stopping condition, GradientDescentLineSearchOptimizerv4Template: Convergence checker passed at iteration 16.\n",
      "Registration successful for patient: BOGER_DAVID_S. Transform saved to D:/CTH_archive/TRANSFORMS_STRIPPED\\BOGER_DAVID_S.h5\n",
      "Final metric value: -0.3112248275323103\n",
      "Optimizer's stopping condition, GradientDescentLineSearchOptimizerv4Template: Convergence checker passed at iteration 28.\n",
      "Registration successful for patient: BROWN_ANTHONY. Transform saved to D:/CTH_archive/TRANSFORMS_STRIPPED\\BROWN_ANTHONY.h5\n",
      "Final metric value: -0.210911506414302\n",
      "Optimizer's stopping condition, GradientDescentLineSearchOptimizerv4Template: Convergence checker passed at iteration 15.\n",
      "Registration successful for patient: CAMPAGNA_HARRY_D. Transform saved to D:/CTH_archive/TRANSFORMS_STRIPPED\\CAMPAGNA_HARRY_D.h5\n",
      "Final metric value: -0.29509743839279406\n",
      "Optimizer's stopping condition, GradientDescentLineSearchOptimizerv4Template: Convergence checker passed at iteration 14.\n",
      "Registration successful for patient: CANIGLIA_ROBERT. Transform saved to D:/CTH_archive/TRANSFORMS_STRIPPED\\CANIGLIA_ROBERT.h5\n",
      "Final metric value: -0.34308584780906093\n",
      "Optimizer's stopping condition, GradientDescentLineSearchOptimizerv4Template: Convergence checker passed at iteration 56.\n",
      "Registration successful for patient: CARDIN_PAUL. Transform saved to D:/CTH_archive/TRANSFORMS_STRIPPED\\CARDIN_PAUL.h5\n",
      "Final metric value: -0.32341016845312043\n",
      "Optimizer's stopping condition, GradientDescentLineSearchOptimizerv4Template: Convergence checker passed at iteration 34.\n",
      "Registration successful for patient: CHANG_WAH_KONG. Transform saved to D:/CTH_archive/TRANSFORMS_STRIPPED\\CHANG_WAH_KONG.h5\n",
      "Final metric value: -0.3069090008737699\n",
      "Optimizer's stopping condition, GradientDescentLineSearchOptimizerv4Template: Convergence checker passed at iteration 14.\n",
      "Registration successful for patient: CHEN_XIU_D. Transform saved to D:/CTH_archive/TRANSFORMS_STRIPPED\\CHEN_XIU_D.h5\n",
      "Final metric value: -0.4214412012909839\n",
      "Optimizer's stopping condition, GradientDescentLineSearchOptimizerv4Template: Convergence checker passed at iteration 57.\n",
      "Registration successful for patient: CHEUNG_SIU-LING_LING_WOO. Transform saved to D:/CTH_archive/TRANSFORMS_STRIPPED\\CHEUNG_SIU-LING_LING_WOO.h5\n",
      "Final metric value: -0.3387796777995972\n",
      "Optimizer's stopping condition, GradientDescentLineSearchOptimizerv4Template: Convergence checker passed at iteration 12.\n",
      "Registration successful for patient: CHOWDHURY_SALMA_K. Transform saved to D:/CTH_archive/TRANSFORMS_STRIPPED\\CHOWDHURY_SALMA_K.h5\n",
      "Final metric value: -0.18080399275934797\n",
      "Optimizer's stopping condition, GradientDescentLineSearchOptimizerv4Template: Convergence checker passed at iteration 16.\n",
      "Registration successful for patient: CLARKSON-FARRELL_EDWARD. Transform saved to D:/CTH_archive/TRANSFORMS_STRIPPED\\CLARKSON-FARRELL_EDWARD.h5\n",
      "Final metric value: -0.3765508901805587\n",
      "Optimizer's stopping condition, GradientDescentLineSearchOptimizerv4Template: Convergence checker passed at iteration 11.\n",
      "Registration successful for patient: COLLADOTORRES_URIBES_A. Transform saved to D:/CTH_archive/TRANSFORMS_STRIPPED\\COLLADOTORRES_URIBES_A.h5\n",
      "Final metric value: -0.2759947934862643\n",
      "Optimizer's stopping condition, GradientDescentLineSearchOptimizerv4Template: Convergence checker passed at iteration 32.\n",
      "Registration successful for patient: COMPRES_THELMA. Transform saved to D:/CTH_archive/TRANSFORMS_STRIPPED\\COMPRES_THELMA.h5\n",
      "Final metric value: -0.30603851489629696\n",
      "Optimizer's stopping condition, GradientDescentLineSearchOptimizerv4Template: Convergence checker passed at iteration 13.\n",
      "Registration successful for patient: COOPER_SUSAN. Transform saved to D:/CTH_archive/TRANSFORMS_STRIPPED\\COOPER_SUSAN.h5\n",
      "Final metric value: -0.17459935533334908\n",
      "Optimizer's stopping condition, GradientDescentLineSearchOptimizerv4Template: Convergence checker passed at iteration 46.\n",
      "Registration successful for patient: CRUZ_MIRIAN. Transform saved to D:/CTH_archive/TRANSFORMS_STRIPPED\\CRUZ_MIRIAN.h5\n",
      "Final metric value: -0.22025120050598343\n",
      "Optimizer's stopping condition, GradientDescentLineSearchOptimizerv4Template: Convergence checker passed at iteration 14.\n",
      "Registration successful for patient: DAMBOISE_JACQUES_J. Transform saved to D:/CTH_archive/TRANSFORMS_STRIPPED\\DAMBOISE_JACQUES_J.h5\n",
      "Final metric value: -0.3306324366393696\n",
      "Optimizer's stopping condition, GradientDescentLineSearchOptimizerv4Template: Convergence checker passed at iteration 13.\n",
      "Registration successful for patient: DEGRAFT_NYUMUTSU_E. Transform saved to D:/CTH_archive/TRANSFORMS_STRIPPED\\DEGRAFT_NYUMUTSU_E.h5\n",
      "Final metric value: -0.37619871786359355\n",
      "Optimizer's stopping condition, GradientDescentLineSearchOptimizerv4Template: Convergence checker passed at iteration 40.\n",
      "Registration successful for patient: DONALDSON_GEORGIANNA. Transform saved to D:/CTH_archive/TRANSFORMS_STRIPPED\\DONALDSON_GEORGIANNA.h5\n",
      "Final metric value: -0.3224116683173672\n",
      "Optimizer's stopping condition, GradientDescentLineSearchOptimizerv4Template: Convergence checker passed at iteration 55.\n",
      "Registration successful for patient: DUMA_ZBIGNIEW. Transform saved to D:/CTH_archive/TRANSFORMS_STRIPPED\\DUMA_ZBIGNIEW.h5\n",
      "Final metric value: -0.33327391696663233\n",
      "Optimizer's stopping condition, GradientDescentLineSearchOptimizerv4Template: Convergence checker passed at iteration 21.\n",
      "Registration successful for patient: EASON_CHARLES. Transform saved to D:/CTH_archive/TRANSFORMS_STRIPPED\\EASON_CHARLES.h5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14812\\1726645171.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfixed_image_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfixed_images_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[0mmoving_image_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmoving_images_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfixed_image_path\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmoving_image_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m         \u001b[0mregister_images\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfixed_image_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmoving_image_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransforms_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14812\\1726645171.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(fixed_image_path, moving_image_path, transforms_dir)\u001b[0m\n\u001b[0;32m     53\u001b[0m                 \u001b[0mregistration_method\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGetOptimizerStopConditionDescription\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m             )\n\u001b[0;32m     55\u001b[0m         )\n\u001b[0;32m     56\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Registration successful for patient: {patient}. Transform saved to {transform_file}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m     \u001b[1;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Registration failed for patient {patient}: {e}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\nprim\\miniconda3\\envs\\fx_bounding_box\\Lib\\site-packages\\SimpleITK\\SimpleITK.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, fixed, moving)\u001b[0m\n\u001b[0;32m  10848\u001b[0m         \u001b[0mOptimize\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mconfigured\u001b[0m \u001b[0mregistration\u001b[0m \u001b[0mproblem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10850\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10851\u001b[0m         \"\"\"\n\u001b[1;32m> 10852\u001b[1;33m         \u001b[0mval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_SimpleITK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mImageRegistrationMethod_Execute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfixed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmoving\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m  10853\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10854\u001b[0m         \u001b[0mval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDowncast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10855\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "transforms_dir = \"D:/CTH_archive/TRANSFORMS_STRIPPED\"\n",
    "if not os.path.exists(transforms_dir):\n",
    "    os.makedirs(transforms_dir)\n",
    "\n",
    "fixed_images_dir = \"D:/CTH_archive/CTH_STRIPPED\"  \n",
    "moving_images_dir = \"D:/CTH_archive/CTP_STRIPPED\" \n",
    "\n",
    "def register_images(fixed_image_path, moving_image_path, transforms_dir):\n",
    "    # Extract patient identifier from the file name, ensuring .nii is not included\n",
    "    patient = os.path.splitext(os.path.basename(moving_image_path))[0]\n",
    "    patient = os.path.splitext(patient)[0]  # Remove .nii if present\n",
    "\n",
    "    # Construct the transform file path\n",
    "    transform_file = os.path.join(transforms_dir, f'{patient}.h5')\n",
    "\n",
    "    # Check if the transform file already exists and skip registration if it does\n",
    "    if os.path.exists(transform_file):\n",
    "        print(f\"Transform file already exists for patient {patient}, skipping registration.\")\n",
    "        return\n",
    "\n",
    "    # Load the fixed and moving images\n",
    "    fixed_image = sitk.ReadImage(fixed_image_path)\n",
    "    moving_image = sitk.ReadImage(moving_image_path)\n",
    "\n",
    "    # Initialize the registration method\n",
    "    registration_method = sitk.ImageRegistrationMethod()\n",
    "    registration_method.SetMetricAsMattesMutualInformation(numberOfHistogramBins=50)\n",
    "    registration_method.SetMetricSamplingPercentage(0.05)\n",
    "    registration_method.SetMetricSamplingStrategy(registration_method.RANDOM)\n",
    "    registration_method.SetOptimizerAsGradientDescentLineSearch(learningRate=0.5, numberOfIterations=200)\n",
    "    registration_method.SetOptimizerScalesFromPhysicalShift()\n",
    "    #registration_method.SetShrinkFactorsPerLevel(shrinkFactors=[8, 4, 2])\n",
    "    #registration_method.SetSmoothingSigmasPerLevel(smoothingSigmas=[4, 2, 1])\n",
    "    registration_method.SmoothingSigmasAreSpecifiedInPhysicalUnitsOn()\n",
    "\n",
    "    # Initialize the transform\n",
    "    initial_transform = sitk.CenteredTransformInitializer(sitk.Cast(fixed_image, moving_image.GetPixelID()), \n",
    "                                                          moving_image, \n",
    "                                                          sitk.AffineTransform(fixed_image.GetDimension()),\n",
    "                                                          sitk.CenteredTransformInitializerFilter.GEOMETRY)\n",
    "    registration_method.SetInitialTransform(initial_transform, True)\n",
    "\n",
    "    try:\n",
    "        # Execute the registration\n",
    "        final_transform = registration_method.Execute(fixed_image, moving_image)\n",
    "        \n",
    "        # Save the transform\n",
    "        sitk.WriteTransform(final_transform, transform_file)\n",
    "        sitk.WriteImage(sitk.Resample(moving_image, fixed_image, final_transform,  sitk.sitkNearestNeighbor), f\"D:/CTH_archive/CTP_STRIPPED_REG/{patient}.nii\")\n",
    "        print(\"Final metric value: {0}\".format(registration_method.GetMetricValue()))\n",
    "        print(\n",
    "            \"Optimizer's stopping condition, {0}\".format(\n",
    "                registration_method.GetOptimizerStopConditionDescription()\n",
    "            )\n",
    "        )\n",
    "        print(f\"Registration successful for patient: {patient}. Transform saved to {transform_file}\")\n",
    "    except RuntimeError as e:\n",
    "        print(f\"Registration failed for patient {patient}: {e}\")\n",
    "\n",
    "\n",
    "for filename in tqdm(os.listdir(fixed_images_dir)):\n",
    "    fixed_image_path = os.path.join(fixed_images_dir, filename)\n",
    "    moving_image_path = os.path.join(moving_images_dir, filename)\n",
    "\n",
    "    if os.path.isfile(fixed_image_path) and os.path.isfile(moving_image_path):\n",
    "        register_images(fixed_image_path, moving_image_path, transforms_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f011fbb85e046ec96c006d5273b3835",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transform file already exists for patient ALFORD_BARBARA, skipping registration.\n",
      "Transform file already exists for patient ALLAH_MAJUSTICE, skipping registration.\n",
      "Transform file already exists for patient BATTLE_MARIA, skipping registration.\n",
      "Transform file already exists for patient BAUM_ROBERT, skipping registration.\n",
      "Transform file already exists for patient BILLIPS_JAMES, skipping registration.\n",
      "Transform file already exists for patient BOGER_DAVID_S, skipping registration.\n",
      "Transform file already exists for patient BROWN_ANTHONY, skipping registration.\n",
      "Transform file already exists for patient CAMPAGNA_HARRY_D, skipping registration.\n",
      "Transform file already exists for patient CANIGLIA_ROBERT, skipping registration.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'itk' has no attribute 'elastix_registration_method'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 60\u001b[0m\n\u001b[0;32m     57\u001b[0m moving_image_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(moving_images_dir, filename)\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(fixed_image_path) \u001b[38;5;129;01mand\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(moving_image_path):\n\u001b[1;32m---> 60\u001b[0m     \u001b[43mregister_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfixed_image_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmoving_image_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransforms_dir\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[2], line 41\u001b[0m, in \u001b[0;36mregister_images\u001b[1;34m(fixed_image_path, moving_image_path, transforms_dir)\u001b[0m\n\u001b[0;32m     37\u001b[0m moving_image \u001b[38;5;241m=\u001b[39m sitk\u001b[38;5;241m.\u001b[39mReadImage(moving_image_path)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Perform registration\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m#resultImage = sitk.Elastix(fixed_image, moving_image)\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m registered_image, params \u001b[38;5;241m=\u001b[39m \u001b[43mitk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43melastix_registration_method\u001b[49m(fixed_image, moving_image)\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# Create a checkerboard image\u001b[39;00m\n\u001b[0;32m     44\u001b[0m checkerboard \u001b[38;5;241m=\u001b[39m sitk\u001b[38;5;241m.\u001b[39mCheckerBoard(fixed_image, registered_image)\n",
      "File \u001b[1;32mc:\\Users\\nprim\\miniconda3\\envs\\fx_bounding_box\\Lib\\site-packages\\itk\\support\\lazy.py:131\u001b[0m, in \u001b[0;36mLazyITKModule.__getattribute__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattribute__\u001b[39m(\u001b[38;5;28mself\u001b[39m, attr):\n\u001b[1;32m--> 131\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[43mtypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mModuleType\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m not_loaded:\n\u001b[0;32m    133\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mget_lock():  \u001b[38;5;66;03m# All but one thread will block here.\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'itk' has no attribute 'elastix_registration_method'"
     ]
    }
   ],
   "source": [
    "import itk\n",
    "import nibabel as nib\n",
    "from totalsegmentator.python_api import totalsegmentator\n",
    "import os\n",
    "import SimpleITK as sitk\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from image_utils import convert_series_to_nifti, quantize_maps\n",
    "%matplotlib widget\n",
    "\n",
    "import gui\n",
    "import registration_gui as rgui\n",
    "\n",
    "transforms_dir = \"D:/CTH_archive/TRANSFORMS_STRIPPED\"\n",
    "\n",
    "if not os.path.exists(transforms_dir):\n",
    "    os.makedirs(transforms_dir)\n",
    "\n",
    "fixed_images_dir = \"D:/CTH_archive/CTH_STRIPPED\"  \n",
    "moving_images_dir = \"D:/CTH_archive/CTP_STRIPPED\" \n",
    "\n",
    "def register_images(fixed_image_path, moving_image_path, transforms_dir):\n",
    "    # Extract patient identifier from the file name, ensuring .nii is not included\n",
    "    patient = os.path.splitext(os.path.basename(moving_image_path))[0]\n",
    "    patient = os.path.splitext(patient)[0]  # Remove .nii if present\n",
    "\n",
    "    # Construct the transform file path\n",
    "    transform_file = os.path.join(transforms_dir, f'{patient}.h5')\n",
    "\n",
    "    # Check if the transform file already exists and skip registration if it does\n",
    "    if os.path.exists(transform_file):\n",
    "        print(f\"Transform file already exists for patient {patient}, skipping registration.\")\n",
    "        return\n",
    "    # Load the fixed and moving images\n",
    "    fixed_image = sitk.ReadImage(fixed_image_path)\n",
    "    moving_image = sitk.ReadImage(moving_image_path)\n",
    "\n",
    "    # Perform registration\n",
    "    #resultImage = sitk.Elastix(fixed_image, moving_image)\n",
    "    registered_image, params = itk.elastix_registration_method(fixed_image, moving_image)\n",
    "\n",
    "    # Create a checkerboard image\n",
    "    checkerboard = sitk.CheckerBoard(fixed_image, registered_image)\n",
    "\n",
    "    # Convert the checkerboard image to a numpy array\n",
    "    checkerboard_np = sitk.GetArrayFromImage(checkerboard)\n",
    "\n",
    "    # Display the checkerboard image\n",
    "    plt.imshow(checkerboard_np, cmap='gray')\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "\n",
    "for filename in tqdm(os.listdir(fixed_images_dir)):\n",
    "    fixed_image_path = os.path.join(fixed_images_dir, filename)\n",
    "    moving_image_path = os.path.join(moving_images_dir, filename)\n",
    "\n",
    "    if os.path.isfile(fixed_image_path) and os.path.isfile(moving_image_path):\n",
    "        register_images(fixed_image_path, moving_image_path, transforms_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import SimpleITK as sitk\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "transforms_dir = \"D:/CTH_archive/TRANSFORMS_STRIPPED\"\n",
    "if not os.path.exists(transforms_dir):\n",
    "    os.makedirs(transforms_dir)\n",
    "\n",
    "fixed_images_dir = \"D:/CTH_archive/CTH_STRIPPED\"  \n",
    "moving_images_dir = \"D:/CTH_archive/CTP_STRIPPED\" \n",
    "\n",
    "def register_images(fixed_image_path, moving_image_path, transforms_dir):\n",
    "    patient = os.path.splitext(os.path.basename(moving_image_path))[0]\n",
    "    patient = os.path.splitext(patient)[0]\n",
    "\n",
    "    transform_file = os.path.join(transforms_dir, f'{patient}.h5')\n",
    "\n",
    "    if os.path.exists(transform_file):\n",
    "        print(f\"Transform file already exists for patient {patient}, skipping registration.\")\n",
    "        return\n",
    "\n",
    "    fixed_image = sitk.ReadImage(fixed_image_path)\n",
    "    moving_image = sitk.ReadImage(moving_image_path)\n",
    "\n",
    "    registration_method = sitk.ImageRegistrationMethod()\n",
    "    registration_method.SetMetricAsMattesMutualInformation(numberOfHistogramBins=50)\n",
    "    registration_method.SetMetricSamplingPercentage(0.6)\n",
    "    registration_method.SetMetricSamplingStrategy(registration_method.RANDOM)\n",
    "    registration_method.SetOptimizerAsGradientDescentLineSearch(learningRate=0.5, numberOfIterations=200)\n",
    "    registration_method.SetOptimizerScalesFromPhysicalShift()\n",
    "    registration_method.SetShrinkFactorsPerLevel(shrinkFactors=[8, 4, 2])\n",
    "    registration_method.SetSmoothingSigmasPerLevel(smoothingSigmas=[4, 2, 1])\n",
    "    registration_method.SmoothingSigmasAreSpecifiedInPhysicalUnitsOn()\n",
    "\n",
    "    initial_transform = sitk.CenteredTransformInitializer(sitk.Cast(fixed_image, moving_image.GetPixelID()), \n",
    "                                                          moving_image, \n",
    "                                                          sitk.AffineTransform(fixed_image.GetDimension()),\n",
    "                                                          sitk.CenteredTransformInitializerFilter.GEOMETRY)\n",
    "    registration_method.SetInitialTransform(initial_transform, True)\n",
    "\n",
    "    try:\n",
    "        final_transform = registration_method.Execute(fixed_image, moving_image)\n",
    "        sitk.WriteTransform(final_transform, transform_file)\n",
    "        print(f\"Registration successful for patient: {patient}. Transform saved to {transform_file}\")\n",
    "\n",
    "        # Visualize and save the registration results\n",
    "        visualize_and_save_registration(fixed_image, moving_image, final_transform, patient)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"Registration failed for patient {patient}: {e}\")\n",
    "\n",
    "def visualize_and_save_registration(fixed_image, moving_image, transform, patient_id):\n",
    "    resampler = sitk.ResampleImageFilter()\n",
    "    resampler.SetReferenceImage(fixed_image)\n",
    "    resampler.SetTransform(transform)\n",
    "    resampler.SetInterpolator(sitk.sitkLinear)\n",
    "    registered_image = resampler.Execute(moving_image)\n",
    "\n",
    "    fixed_image_array = sitk.GetArrayFromImage(fixed_image)\n",
    "    registered_image_array = sitk.GetArrayFromImage(registered_image)\n",
    "\n",
    "    slice_indices = [fixed_image_array.shape[0] // 4, fixed_image_array.shape[0] // 2]  # Save quarter and middle slices\n",
    "\n",
    "    for idx, slice_idx in enumerate(slice_indices):\n",
    "        fixed_slice = fixed_image_array[slice_idx, :, :]\n",
    "        registered_slice = registered_image_array[slice_idx, :, :]\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(6, 6))\n",
    "        ax.imshow(fixed_slice, cmap='gray')\n",
    "        ax.imshow(registered_slice, cmap='hot', alpha=0.5)  # Overlay the registered image\n",
    "        ax.axis('off')\n",
    "        plt.savefig(f'D:/CTH_archive/Registration_Visualization/{patient_id}_slice_{idx}.png', bbox_inches='tight')\n",
    "        plt.close(fig)  # Ensure the figure is closed and not displayed\n",
    "\n",
    "\n",
    "# Process each image pair\n",
    "for filename in os.listdir(fixed_images_dir):\n",
    "    fixed_image_path = os.path.join(fixed_images_dir, filename)\n",
    "    moving_image_path = os.path.join(moving_images_dir, filename)\n",
    "\n",
    "    if os.path.isfile(fixed_image_path) and os.path.isfile(moving_image_path):\n",
    "        register_images(fixed_image_path, moving_image_path, transforms_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_image(moving_image, fixed_image, ctp_image):\n",
    "    desired_size = [fixed_image.GetSize()[0], fixed_image.GetSize()[1], ctp_image.GetSize()[2]]\n",
    "    resampler = sitk.ResampleImageFilter()\n",
    "    resampler.SetReferenceImage(moving_image)\n",
    "    resampler.SetSize(desired_size)\n",
    "    resampler.SetOutputSpacing([moving_image.GetSpacing()[i] * (moving_image.GetSize()[i] / desired_size[i]) for i in range(3)])\n",
    "    resampler.SetTransform(sitk.Transform())\n",
    "    resampler.SetInterpolator(sitk.sitkLinear)\n",
    "    resized_moving_image = resampler.Execute(moving_image)\n",
    "    resized_moving_image.SetSpacing(ctp_image.GetSpacing())\n",
    "    resized_moving_image.SetOrigin(ctp_image.GetOrigin())\n",
    "    resized_moving_image.SetDirection(ctp_image.GetDirection())\n",
    "    return resized_moving_image\n",
    "\n",
    "def apply_final_transform(resized_moving_image, fixed_image, transform_file_path):\n",
    "    final_transform = sitk.ReadTransform(transform_file_path)\n",
    "    resampled_image = sitk.Resample(resized_moving_image, \n",
    "                                    fixed_image, \n",
    "                                    final_transform, \n",
    "                                    sitk.sitkLinear, \n",
    "                                    0.0, \n",
    "                                    fixed_image.GetPixelID())\n",
    "    return resampled_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: D:\\CTH_archive\\CTP_STRIPPED_REG\\BATTLE_MARIA.nii\n",
      "Dimensions: 3\n",
      "Size: (512, 680, 31)\n",
      "Spacing: (0.302734375, 0.30294114351272583, 4.999999046325684)\n",
      "Origin: (-68.8271484375, -338.61474609375, 1256.77099609375)\n",
      "Direction: (0.9968748471280338, -0.07146105755660387, 0.03367277710381495, 0.056727485700367196, 0.9442108032441664, 0.3244193678856795, -0.05497755477987119, -0.32149537522318694, 0.9453138197565785)\n",
      "Pixel Type: 64-bit float\n",
      "Number of Components per Pixel: 1\n",
      "--------------------------------------------------\n",
      "File: D:\\CTH_archive\\CTP_STRIPPED\\BATTLE_MARIA.nii\n",
      "Dimensions: 3\n",
      "Size: (512, 512, 149)\n",
      "Spacing: (0.390625, 0.390625, 1.0)\n",
      "Origin: (-99.8046875, -328.8046875, 143.8000030517578)\n",
      "Direction: (1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0)\n",
      "Pixel Type: 64-bit float\n",
      "Number of Components per Pixel: 1\n",
      "--------------------------------------------------\n",
      "File: D:\\CTH_archive\\TMAX_NIFTI_QUANT\\REGISTERED\\BATTLE_MARIA.nii\n",
      "Dimensions: 3\n",
      "Size: (512, 680, 31)\n",
      "Spacing: (0.302734375, 0.30294114351272583, 4.999999046325684)\n",
      "Origin: (-68.8271484375, -338.61474609375, 1256.77099609375)\n",
      "Direction: (0.9968748471280338, -0.07146105755660387, 0.03367277710381495, 0.056727485700367196, 0.9442108032441664, 0.3244193678856795, -0.05497755477987119, -0.32149537522318694, 0.9453138197565785)\n",
      "Pixel Type: 64-bit float\n",
      "Number of Components per Pixel: 1\n",
      "--------------------------------------------------\n",
      "File: D:\\CTH_archive\\CTH_STRIPPED\\BATTLE_MARIA.nii\n",
      "Dimensions: 3\n",
      "Size: (512, 680, 31)\n",
      "Spacing: (0.302734375, 0.30294114351272583, 4.999999046325684)\n",
      "Origin: (-68.8271484375, -338.61474609375, 1256.77099609375)\n",
      "Direction: (0.9968748471280338, -0.0714610559057785, 0.03367277710381495, 0.056727485700367196, 0.944210798568239, 0.3244193678856795, -0.05497755477987119, -0.3214953893230195, 0.9453138197565785)\n",
      "Pixel Type: 64-bit float\n",
      "Number of Components per Pixel: 1\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import SimpleITK as sitk\n",
    "\n",
    "# Paths to your NIfTI files\n",
    "files = [\n",
    "    \"D:\\\\CTH_archive\\\\CTP_STRIPPED_REG\\\\BATTLE_MARIA.nii\",\n",
    "    \"D:\\\\CTH_archive\\\\CTP_STRIPPED\\\\BATTLE_MARIA.nii\",\n",
    "    \"D:\\\\CTH_archive\\\\TMAX_NIFTI_QUANT\\\\REGISTERED\\\\BATTLE_MARIA.nii\",\n",
    "    \"D:\\\\CTH_archive\\\\CTH_STRIPPED\\\\BATTLE_MARIA.nii\"\n",
    "]\n",
    "\n",
    "# Loop through each file and print out the relevant information\n",
    "for file_path in files:\n",
    "    try:\n",
    "        # Read the image file\n",
    "        image = sitk.ReadImage(file_path)\n",
    "        \n",
    "        # Print out relevant information\n",
    "        print(f\"File: {file_path}\")\n",
    "        print(f\"Dimensions: {image.GetDimension()}\")\n",
    "        print(f\"Size: {image.GetSize()}\")\n",
    "        print(f\"Spacing: {image.GetSpacing()}\")\n",
    "        print(f\"Origin: {image.GetOrigin()}\")\n",
    "        print(f\"Direction: {image.GetDirection()}\")\n",
    "        print(f\"Pixel Type: {image.GetPixelIDTypeAsString()}\")\n",
    "        print(f\"Number of Components per Pixel: {image.GetNumberOfComponentsPerPixel()}\")\n",
    "        print(\"-\" * 50)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to read {file_path}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ALFORD_BARBARA...\n",
      "Processed and saved: D:/CTH_archive/TMAX_NIFTI_QUANT\\REGISTERED\\ALFORD_BARBARA.nii\n",
      "Processing ALLAH_MAJUSTICE...\n",
      "Processed and saved: D:/CTH_archive/TMAX_NIFTI_QUANT\\REGISTERED\\ALLAH_MAJUSTICE.nii\n",
      "Processing BATTLE_MARIA...\n",
      "Processed and saved: D:/CTH_archive/TMAX_NIFTI_QUANT\\REGISTERED\\BATTLE_MARIA.nii\n",
      "Processing BAUM_ROBERT...\n",
      "Processed and saved: D:/CTH_archive/TMAX_NIFTI_QUANT\\REGISTERED\\BAUM_ROBERT.nii\n",
      "Processing BILLIPS_JAMES...\n",
      "Processed and saved: D:/CTH_archive/TMAX_NIFTI_QUANT\\REGISTERED\\BILLIPS_JAMES.nii\n",
      "Processing BOGER_DAVID_S...\n",
      "Processed and saved: D:/CTH_archive/TMAX_NIFTI_QUANT\\REGISTERED\\BOGER_DAVID_S.nii\n",
      "Processing BROWN_ANTHONY...\n",
      "Processed and saved: D:/CTH_archive/TMAX_NIFTI_QUANT\\REGISTERED\\BROWN_ANTHONY.nii\n",
      "Processing CAMPAGNA_HARRY_D...\n",
      "Processed and saved: D:/CTH_archive/TMAX_NIFTI_QUANT\\REGISTERED\\CAMPAGNA_HARRY_D.nii\n",
      "Processing CANIGLIA_ROBERT...\n",
      "Processed and saved: D:/CTH_archive/TMAX_NIFTI_QUANT\\REGISTERED\\CANIGLIA_ROBERT.nii\n",
      "Processing CARDIN_PAUL...\n",
      "Processed and saved: D:/CTH_archive/TMAX_NIFTI_QUANT\\REGISTERED\\CARDIN_PAUL.nii\n",
      "Processing CHANG_WAH_KONG...\n",
      "Processed and saved: D:/CTH_archive/TMAX_NIFTI_QUANT\\REGISTERED\\CHANG_WAH_KONG.nii\n",
      "Processing CHEN_XIU_D...\n",
      "Processed and saved: D:/CTH_archive/TMAX_NIFTI_QUANT\\REGISTERED\\CHEN_XIU_D.nii\n",
      "Processing CHEUNG_SIU-LING_LING_WOO...\n",
      "Processed and saved: D:/CTH_archive/TMAX_NIFTI_QUANT\\REGISTERED\\CHEUNG_SIU-LING_LING_WOO.nii\n",
      "Processing CHOWDHURY_SALMA_K...\n",
      "Processed and saved: D:/CTH_archive/TMAX_NIFTI_QUANT\\REGISTERED\\CHOWDHURY_SALMA_K.nii\n",
      "Processing CLARKSON-FARRELL_EDWARD...\n",
      "Processed and saved: D:/CTH_archive/TMAX_NIFTI_QUANT\\REGISTERED\\CLARKSON-FARRELL_EDWARD.nii\n",
      "Processing COLLADOTORRES_URIBES_A...\n",
      "Processed and saved: D:/CTH_archive/TMAX_NIFTI_QUANT\\REGISTERED\\COLLADOTORRES_URIBES_A.nii\n",
      "Processing COMPRES_THELMA...\n",
      "Processed and saved: D:/CTH_archive/TMAX_NIFTI_QUANT\\REGISTERED\\COMPRES_THELMA.nii\n",
      "Processing COOPER_SUSAN...\n",
      "Processed and saved: D:/CTH_archive/TMAX_NIFTI_QUANT\\REGISTERED\\COOPER_SUSAN.nii\n",
      "Processing CRUZ_MIRIAN...\n",
      "Processed and saved: D:/CTH_archive/TMAX_NIFTI_QUANT\\REGISTERED\\CRUZ_MIRIAN.nii\n",
      "Processing DAMBOISE_JACQUES_J...\n",
      "Processed and saved: D:/CTH_archive/TMAX_NIFTI_QUANT\\REGISTERED\\DAMBOISE_JACQUES_J.nii\n",
      "Processing DEGRAFT_NYUMUTSU_E...\n",
      "Processed and saved: D:/CTH_archive/TMAX_NIFTI_QUANT\\REGISTERED\\DEGRAFT_NYUMUTSU_E.nii\n",
      "Processing DONALDSON_GEORGIANNA...\n",
      "Processed and saved: D:/CTH_archive/TMAX_NIFTI_QUANT\\REGISTERED\\DONALDSON_GEORGIANNA.nii\n",
      "Processing DUMA_ZBIGNIEW...\n",
      "Processed and saved: D:/CTH_archive/TMAX_NIFTI_QUANT\\REGISTERED\\DUMA_ZBIGNIEW.nii\n",
      "Processing EASON_CHARLES...\n",
      "Processed and saved: D:/CTH_archive/TMAX_NIFTI_QUANT\\REGISTERED\\EASON_CHARLES.nii\n"
     ]
    }
   ],
   "source": [
    "import SimpleITK as sitk\n",
    "import logging\n",
    "\n",
    "def resample_image(moving_image, fixed_image, ctp_image):\n",
    "    desired_size = [512, 512, ctp_image.GetSize()[2]]\n",
    "    resampler = sitk.ResampleImageFilter()\n",
    "    resampler.SetReferenceImage(moving_image)\n",
    "    resampler.SetSize(desired_size)\n",
    "    resampler.SetOutputSpacing([moving_image.GetSpacing()[i] * (moving_image.GetSize()[i] / desired_size[i]) for i in range(3)])\n",
    "    #resampler.SetTransform(sitk.Transform())\n",
    "    resampler.SetInterpolator(sitk.sitkLinear)\n",
    "    resized_moving_image = resampler.Execute(moving_image)\n",
    "    resized_moving_image.SetSpacing(ctp_image.GetSpacing())\n",
    "    resized_moving_image.SetOrigin(ctp_image.GetOrigin())\n",
    "    resized_moving_image.SetDirection(ctp_image.GetDirection())\n",
    "    return resized_moving_image\n",
    "\n",
    "def apply_final_transform(resized_moving_image, fixed_image, transform_file_path):\n",
    "    final_transform = sitk.ReadTransform(transform_file_path)\n",
    "    resampled_image = sitk.Resample(resized_moving_image, \n",
    "                                    fixed_image, \n",
    "                                    final_transform, \n",
    "                                    sitk.sitkNearestNeighbor, \n",
    "                                    0.0, \n",
    "                                    fixed_image.GetPixelID())\n",
    "    return resampled_image\n",
    "\n",
    "def apply_final_transform(resized_moving_image, fixed_image, transform_file_path):\n",
    "    try:\n",
    "        final_transform = sitk.ReadTransform(transform_file_path)\n",
    "        \n",
    "        # Ensure the resized_moving_image is valid before proceeding\n",
    "        if resized_moving_image:\n",
    "            resampled_image = sitk.Resample(resized_moving_image, \n",
    "                                            fixed_image, \n",
    "                                            final_transform, \n",
    "                                            sitk.sitkLinear, \n",
    "                                            0.0, \n",
    "                                            fixed_image.GetPixelID())\n",
    "            return resampled_image\n",
    "        else:\n",
    "            logging.error(\"Resized moving image is invalid. Cannot apply final transform.\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        logging.error(\"Failed to apply final transform: \" + str(e))\n",
    "        return None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Directories\n",
    "tmax_nifti_dir = r\"D:/CTH_archive/TMAX_NIFTI_QUANT\"\n",
    "transforms_dir = r\"D:/CTH_archive/TRANSFORMS_STRIPPED\"\n",
    "cth_stripped_dir = r\"D:/CTH_archive/CTH_STRIPPED\"\n",
    "ctp_stripped_dir = r\"D:/CTH_archive/CTP_STRIPPED\"\n",
    "output_dir = os.path.join(tmax_nifti_dir, \"REGISTERED\")\n",
    "\n",
    "# Ensure the output directory exists\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Iterate over the transformation files\n",
    "for transform_file in os.listdir(transforms_dir):\n",
    "    transform_path = os.path.join(transforms_dir, transform_file)\n",
    "    base_filename = transform_file.replace('.h5', '')\n",
    "\n",
    "    # Paths to the moving, fixed, and reference (ctp) images\n",
    "    moving_image_path = os.path.join(tmax_nifti_dir, base_filename + '.nii')\n",
    "    fixed_image_path = os.path.join(cth_stripped_dir, base_filename + '.nii')\n",
    "    ctp_image_path = os.path.join(ctp_stripped_dir, base_filename + '.nii')\n",
    "    print(f\"Processing {base_filename}...\")\n",
    "\n",
    "    # Check if all required files exist\n",
    "    if os.path.exists(moving_image_path) and os.path.exists(fixed_image_path) and os.path.exists(ctp_image_path):\n",
    "        # Load images\n",
    "        moving_image = sitk.ReadImage(moving_image_path)\n",
    "        fixed_image = sitk.ReadImage(fixed_image_path)\n",
    "        ctp_image = sitk.ReadImage(ctp_image_path)\n",
    "\n",
    "        # Resample the moving image\n",
    "        resized_moving_image = resample_image(moving_image, fixed_image, ctp_image)\n",
    "\n",
    "        # Apply the final transformation\n",
    "        resampled_image = apply_final_transform(resized_moving_image, fixed_image, transform_path)\n",
    "\n",
    "        # Save the resampled image\n",
    "        resampled_image_path = os.path.join(output_dir, base_filename + '.nii')\n",
    "        sitk.WriteImage(resampled_image, resampled_image_path)\n",
    "        print(f\"Processed and saved: {resampled_image_path}\")\n",
    "    else:\n",
    "        print(f\"Required files for {base_filename} are not available.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "# Directory containing the files\n",
    "directory_path = \"D:\\\\CTH_archive\\\\CTP_STRIPPED\"\n",
    "\n",
    "# Iterate over all files in the directory\n",
    "for filename in os.listdir(directory_path):\n",
    "    # Full path of the current file\n",
    "    original_path = os.path.join(directory_path, filename)\n",
    "\n",
    "    # Skip directories, process only files\n",
    "    if os.path.isfile(original_path):\n",
    "        # Remove numeric pattern and the word 'transform' from the filename\n",
    "        new_filename = re.sub(r\"_\\d+|_transform\", \"\", filename)\n",
    "\n",
    "        # Full path for the new file name\n",
    "        new_path = os.path.join(directory_path, new_filename)\n",
    "\n",
    "        # Rename the file\n",
    "        os.rename(original_path, new_path)\n",
    "        print(f\"Renamed '{original_path}' to '{new_path}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_label_intensities(label_dir, output_dir):\n",
    "    # Ensure the output directory exists, create if it doesn't\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    # Iterate over all files in the label directory\n",
    "    for file_name in os.listdir(label_dir):\n",
    "        if file_name.endswith('.nii'):\n",
    "            file_path = os.path.join(label_dir, file_name)\n",
    "\n",
    "            # Load the label file\n",
    "            label_image = nib.load(file_path)\n",
    "            label_data = label_image.get_fdata()\n",
    "\n",
    "            # Modify non-zero intensities\n",
    "            non_background_mask = label_data > 0\n",
    "            label_data[non_background_mask] = np.round(label_data[non_background_mask])\n",
    "\n",
    "            # Create a new NIfTI image object with the adjusted data\n",
    "            adjusted_label_image = nib.Nifti1Image(label_data, affine=label_image.affine, header=label_image.header)\n",
    "\n",
    "            # Define the output file path\n",
    "            output_file_path = os.path.join(output_dir, file_name)\n",
    "\n",
    "            # Save the adjusted data to the new file in the output directory\n",
    "            nib.save(adjusted_label_image, output_file_path)\n",
    "            print(f\"Adjusted and saved: {output_file_path}\")\n",
    "\n",
    "# Directory containing the quantized label files\n",
    "label_dir = r\"D:\\CTH_archive\\TMAX_NIFTI_QUANT\\REGISTERED\"\n",
    "\n",
    "# New output directory for adjusted label files\n",
    "output_dir = r\"D:\\CTH_archive\\TMAX_NIFTI_QUANT\\REGISTERED_ADJUSTED\"\n",
    "\n",
    "# Call the function to adjust label intensities and save to the new directory\n",
    "adjust_label_intensities(label_dir, output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# List of directories to check\n",
    "directories = [\n",
    "    \"D:\\\\CTH_archive\\\\CTH_NIFTI\",\n",
    "    \"D:\\\\CTH_archive\\\\CTH_STRIPPED\",\n",
    "    \"D:\\\\CTH_archive\\\\CTH_STRIPPED_MASK\",\n",
    "    \"D:\\\\CTH_archive\\\\CTP_NIFTI\",\n",
    "    \"D:\\\\CTH_archive\\\\CTP_STRIPPED\",\n",
    "    \"D:\\\\CTH_archive\\\\CTP_STRIPPED_MASK\",\n",
    "    \"D:\\\\CTH_archive\\\\TMAX_NIFTI\",\n",
    "    \"D:\\\\CTH_archive\\\\TMAX_NIFTI_QUANT\"\n",
    "]\n",
    "\n",
    "# Dictionary to hold the set of file base names (without extension) for each directory\n",
    "file_sets = {}\n",
    "\n",
    "# Extract and store the base names of the files in each directory\n",
    "for directory in directories:\n",
    "    file_names = [os.path.splitext(f)[0] for f in os.listdir(directory) if os.path.isfile(os.path.join(directory, f))]\n",
    "    file_sets[directory] = set(file_names)\n",
    "\n",
    "# Use the first directory as the reference for comparison\n",
    "reference_files = list(file_sets.values())[0]\n",
    "reference_dir = directories[0]\n",
    "\n",
    "# Compare the file sets of each directory against the reference\n",
    "for directory, file_set in file_sets.items():\n",
    "    if directory == reference_dir:\n",
    "        continue  # Skip the reference directory itself\n",
    "    \n",
    "    # Determine missing and extra files relative to the reference\n",
    "    missing_files = reference_files - file_set\n",
    "    extra_files = file_set - reference_files\n",
    "\n",
    "    # Print out any discrepancies\n",
    "    if missing_files:\n",
    "        print(f\"Missing files in {directory} (present in {reference_dir} but not here):\")\n",
    "        for file in missing_files:\n",
    "            print(f\"  {file}\")\n",
    "        print()\n",
    "\n",
    "    if extra_files:\n",
    "        print(f\"Extra files in {directory} (not present in {reference_dir}):\")\n",
    "        for file in extra_files:\n",
    "            print(f\"  {file}\")\n",
    "        print()\n",
    "\n",
    "if not any([missing_files, extra_files]):\n",
    "    print(\"All directories contain the same files, ignoring extensions.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nibabel as nib\n",
    "\n",
    "# Directory containing .nii.gz files\n",
    "directory = 'D:\\CTH_archive\\CTP_STRIPPED'\n",
    "\n",
    "# Iterate over all files in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    # Check if the file is a .nii.gz file\n",
    "    if filename.endswith('.nii.gz'):\n",
    "        # Construct the full file path\n",
    "        file_path = os.path.join(directory, filename)\n",
    "\n",
    "        # Load the .nii.gz file\n",
    "        nii_file = nib.load(file_path)\n",
    "\n",
    "        # Construct the new file name with .nii extension\n",
    "        new_file_path = file_path[:-3]  # Remove 'gz' from the end\n",
    "\n",
    "        # Save the file as .nii\n",
    "        nib.save(nii_file, new_file_path)\n",
    "\n",
    "        # Optionally, remove the original .nii.gz file\n",
    "        # os.remove(file_path)\n",
    "\n",
    "        print(f'Converted {filename} to .nii format.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nibabel as nib\n",
    "import shutil\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "num_test_files = 5\n",
    "\n",
    "\n",
    "def convert_and_copy_with_labels_and_rename(image_source_dir, image_target_dir, label_source_dir, label_target_dir, images_test_dir, labels_test_dir):\n",
    "    # Ensure all target directories exist, create if they don't\n",
    "    for dir_path in [image_target_dir, label_target_dir, images_test_dir, labels_test_dir]:\n",
    "        if not os.path.exists(dir_path):\n",
    "            os.makedirs(dir_path)\n",
    "\n",
    "    # List all .nii files in the source directory\n",
    "    all_files = [f for f in sorted(os.listdir(image_source_dir)) if f.endswith('.nii')]\n",
    "    \n",
    "    # Determine the number of files to sample, ensuring it's not more than the total number of files available\n",
    "    num_test_files = min(5, len(all_files))\n",
    "\n",
    "    # Randomly select files for testing, based on the determined number\n",
    "    test_files = random.sample(all_files, num_test_files)\n",
    "\n",
    "    # Move selected test files and their labels\n",
    "    for file_name in tqdm(test_files, desc=\"Moving test files\"):\n",
    "        shutil.move(os.path.join(image_source_dir, file_name), os.path.join(images_test_dir, file_name))\n",
    "        \n",
    "        # Adjust the file name for the label to match the .nii extension\n",
    "        label_file_name = file_name.replace('.nii.gz', '.nii') if file_name.endswith('.nii.gz') else file_name\n",
    "        shutil.move(os.path.join(label_source_dir, label_file_name), os.path.join(labels_test_dir, label_file_name))\n",
    "        print(f\"Moved {file_name} and its label to the test directories.\")\n",
    "\n",
    "    # Remove test files from the all_files list\n",
    "    for test_file in test_files:\n",
    "        all_files.remove(test_file)\n",
    "\n",
    "    # Initialize a counter for unique naming within the training set\n",
    "    counter = 1\n",
    "\n",
    "    # Iterate over the remaining files for training\n",
    "    for file_name in tqdm(all_files, desc=\"Processing training files\"):\n",
    "        # Construct full source file paths for images and labels\n",
    "        image_source_file_path = os.path.join(image_source_dir, file_name)\n",
    "        label_source_file_path = os.path.join(label_source_dir, file_name)\n",
    "\n",
    "        # Load the .nii file (image)\n",
    "        nii_image = nib.load(image_source_file_path)\n",
    "\n",
    "        # Construct the new file name for images and labels\n",
    "        base_name = file_name[:-4]  # Remove .nii extension\n",
    "        new_image_name = f\"{base_name}_{counter:03d}_0000.nii.gz\"\n",
    "        new_label_name = f\"{base_name}_{counter:03d}.nii.gz\"\n",
    "\n",
    "        # Construct target file paths\n",
    "        image_target_file_path = os.path.join(image_target_dir, new_image_name)\n",
    "        label_target_file_path = os.path.join(label_target_dir, new_label_name)\n",
    "\n",
    "        # Save the image file as .nii.gz in the target directory\n",
    "        nib.save(nii_image, image_target_file_path)\n",
    "        print(f\"Converted and copied image: {image_source_file_path} to {image_target_file_path}\")\n",
    "\n",
    "        # Load the .nii file (label)\n",
    "        nii_label = nib.load(label_source_file_path)\n",
    "\n",
    "        # Save the label file as .nii.gz in the target directory\n",
    "        nib.save(nii_label, label_target_file_path)\n",
    "        print(f\"Converted and copied label: {label_source_file_path} to {label_target_file_path}\")\n",
    "\n",
    "        # Increment the counter for unique naming\n",
    "        counter += 1\n",
    "\n",
    "# Define source and target directories for images and labels\n",
    "image_source_dir = r\"D:/CTH_archive/CTH_STRIPPED\"\n",
    "image_target_dir = r\"D:/nnUNet_raw/Dataset039_Perfusion/imagesTr\"\n",
    "label_source_dir = r\"D:/CTH_archive/TMAX_NIFTI_QUANT/REGISTERED_ADJUSTED\"\n",
    "label_target_dir = r\"D:/nnUNet_raw/Dataset039_Perfusion/labelsTr\"\n",
    "\n",
    "# Define target directories for testing\n",
    "images_test_dir = r\"D:/nnUNet_raw/Dataset039_Perfusion/imagesTs\"\n",
    "labels_test_dir = r\"D:/nnUNet_raw/Dataset039_Perfusion/labelsTs\"\n",
    "\n",
    "convert_and_copy_with_labels_and_rename(image_source_dir, image_target_dir, label_source_dir, label_target_dir, images_test_dir, labels_test_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "def generate_dataset_json(dataset_dir, num_quant_levels, channel_names, nnUNet_dir, file_ending=\".nii.gz\", num_test_data=0):\n",
    "    \"\"\"\n",
    "    Generate a dataset.json file for the given dataset with dynamic quantization levels.\n",
    "\n",
    "    Args:\n",
    "    - dataset_dir (str): Directory where the dataset files are stored.\n",
    "    - num_quant_levels (int): Number of quantization levels (excluding the background).\n",
    "    - channel_names (dict): Mapping of channel indices to their names.\n",
    "    - file_ending (str): File extension of the dataset files.\n",
    "    - num_test_data (int): The number of the dataset to be used for testing.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    # Dynamically generate labels based on the number of quantization levels\n",
    "    labels = {\"background\": \"0\"}\n",
    "    for i in range(1, num_quant_levels + 1):\n",
    "        labels[f\"quantized_{i}\"] = str(i)\n",
    "\n",
    "    # Count the number of dataset files\n",
    "    num_training = len([file for file in os.listdir(dataset_dir) if file.endswith(file_ending)])\n",
    "\n",
    "    # Use the specified number of test data and calculate the remaining number of training files\n",
    "    num_test = num_test_data\n",
    "\n",
    "    # Construct the dataset JSON structure\n",
    "    dataset_json = {\n",
    "        \"labels\": labels,\n",
    "        \"numTraining\": num_training,\n",
    "        \"numTest\": num_test,\n",
    "        \"channel_names\": channel_names,\n",
    "        \"file_ending\": file_ending\n",
    "    }\n",
    "\n",
    "    # Write the JSON structure to a file\n",
    "    with open(os.path.join(nnUNet_dir, \"dataset.json\"), 'w') as json_file:\n",
    "        json.dump(dataset_json, json_file, indent=4)\n",
    "\n",
    "    print(f\"dataset.json file has been generated in {nnUNet_dir}\")\n",
    "\n",
    "# Example usage\n",
    "dataset_dir = r'D:\\nnUNet_raw\\Dataset039_Perfusion\\labelsTr'  # Path to dataset directory\n",
    "nnUNet_dir = r'D:\\nnUNet_raw\\Dataset039_Perfusion'  # Path to nnUNet directory\n",
    "num_quant_levels = 5  # Number of quantization levels (excluding background)\n",
    "channel_names = {\"0\": \"CT\"}\n",
    "num_test_data = 5  # Specify the number of test data\n",
    "\n",
    "generate_dataset_json(dataset_dir, num_quant_levels, channel_names, nnUNet_dir, file_ending=\".nii.gz\", num_test_data=num_test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interactive, IntSlider, Dropdown\n",
    "\n",
    "prediction_dir = r\"D:\\CTH_archive\\CTP_STRIPPED\"\n",
    "ground_truth_dir = r\"D:\\CTH_archive\\TMAX_NIFTI_QUANT\\REGISTERED\"  # Updated path for ground truth images\n",
    "ct_images_dir = r\"D:\\CTH_archive\\CTH_NIFTI\"  # Directory for CT head images\n",
    "\n",
    "# Get the .nii.gz files in the directories\n",
    "prediction_files = sorted([f for f in os.listdir(prediction_dir) if f.endswith('.nii') or f.endswith('.nii.gz')])\n",
    "ground_truth_files = sorted([f for f in os.listdir(ground_truth_dir) if f.endswith('.nii') or f.endswith('.nii.gz')])\n",
    "ct_image_files = sorted([f for f in os.listdir(ct_images_dir) if f.endswith('.nii') or f.endswith('.nii.gz')])\n",
    "\n",
    "def apply_window(image, level=40, width=80):\n",
    "    lower = level - (width / 2)\n",
    "    upper = level + (width / 2)\n",
    "    return np.clip((image - lower) / (upper - lower), 0, 1)\n",
    "\n",
    "def plot_images(prediction_file, ground_truth_file, ct_image_file, slice_idx):\n",
    "    # Load the files\n",
    "    prediction_img = nib.load(os.path.join(prediction_dir, prediction_file))\n",
    "    ground_truth_img = nib.load(os.path.join(ground_truth_dir, ground_truth_file))\n",
    "    ct_img = nib.load(os.path.join(ct_images_dir, ct_image_file))\n",
    "\n",
    "    # Convert the data to numpy arrays\n",
    "    prediction_data = prediction_img.get_fdata()\n",
    "    ground_truth_data = ground_truth_img.get_fdata()\n",
    "    ct_data = ct_img.get_fdata()\n",
    "\n",
    "    # Apply custom windowing to the CT head image\n",
    "    ct_data_windowed = apply_window(ct_data)\n",
    "\n",
    "    # Plot the ground truth image, the prediction, the windowed CT head image, and the windowed CT with ground truth overlay\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(20, 5))\n",
    "    axes[0].imshow(ground_truth_data[:, :, slice_idx], cmap='gray')\n",
    "    axes[0].set_title('Ground Truth Image')\n",
    "    axes[1].imshow(prediction_data[:, :, slice_idx], cmap='gray')\n",
    "    axes[1].set_title('Prediction')\n",
    "    axes[2].imshow(ct_data_windowed[:, :, slice_idx], cmap='gray')  # Show the windowed CT head image\n",
    "    axes[2].set_title('Windowed CT Head Image')\n",
    "    axes[3].imshow(ct_data_windowed[:, :, slice_idx], cmap='gray')  # Show the windowed CT head image again for overlay\n",
    "    axes[3].imshow(ground_truth_data[:, :, slice_idx], cmap='hot', alpha=0.5)  # Overlay the ground truth\n",
    "    axes[3].set_title('CT with Ground Truth Overlay')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Create widgets for file selection and slice index\n",
    "prediction_file_widget = Dropdown(options=prediction_files)\n",
    "ground_truth_file_widget = Dropdown(options=ground_truth_files)\n",
    "ct_image_file_widget = Dropdown(options=ct_image_files)\n",
    "slice_idx_widget = IntSlider(min=0, max=1, step=1, value=0)  # Initial max and value set to 0\n",
    "\n",
    "# Create an interactive plot\n",
    "plot = interactive(plot_images, prediction_file=prediction_file_widget, ground_truth_file=ground_truth_file_widget, ct_image_file=ct_image_file_widget, slice_idx=slice_idx_widget)\n",
    "\n",
    "# Update the maximum value and value of the slice index slider whenever a new CT image is selected\n",
    "def update_slice_idx_range(*args):\n",
    "    ct_img = nib.load(os.path.join(ct_images_dir, ct_image_file_widget.value))\n",
    "    ct_data = ct_img.get_fdata()\n",
    "    slice_idx_widget.max = ct_data.shape[2] - 1\n",
    "    slice_idx_widget.value = min(slice_idx_widget.value, slice_idx_widget.max)\n",
    "\n",
    "ct_image_file_widget.observe(update_slice_idx_range, 'value')\n",
    "\n",
    "# Manually call the update function to set the initial max value of the slice index slider\n",
    "update_slice_idx_range()\n",
    "\n",
    "# Display the interactive plot\n",
    "display(plot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import Dropdown, IntSlider, interactive\n",
    "\n",
    "# Base directory paths\n",
    "prediction_dir = r\"D:\\CTH_archive\\CTP_STRIPPED\"\n",
    "ground_truth_dir = r\"D:\\CTH_archive\\TMAX_NIFTI_QUANT\\REGISTERED_ADJUSTED\"\n",
    "ct_images_dir = r\"D:\\CTH_archive\\CTH_STRIPPED\"\n",
    "\n",
    "# Assuming all base filenames are the same across directories, we can just list files from one directory\n",
    "file_options = sorted([f for f in os.listdir(ct_images_dir) if f.endswith('.nii') or f.endswith('.nii.gz')])\n",
    "\n",
    "def apply_window(image, level=40, width=80):\n",
    "    lower = level - (width / 2)\n",
    "    upper = level + (width / 2)\n",
    "    return np.clip((image - lower) / (upper - lower), 0, 1)\n",
    "\n",
    "def plot_images(selected_file, slice_idx):\n",
    "    # Construct file paths for each type of image using the selected file\n",
    "    prediction_file_path = os.path.join(prediction_dir, selected_file)\n",
    "    ground_truth_file_path = os.path.join(ground_truth_dir, selected_file)\n",
    "    ct_image_file_path = os.path.join(ct_images_dir, selected_file)\n",
    "\n",
    "    # Load the files\n",
    "    prediction_img = nib.load(prediction_file_path)\n",
    "    ground_truth_img = nib.load(ground_truth_file_path)\n",
    "    ct_img = nib.load(ct_image_file_path)\n",
    "\n",
    "    # Convert the data to numpy arrays\n",
    "    prediction_data = prediction_img.get_fdata()\n",
    "    ground_truth_data = ground_truth_img.get_fdata()\n",
    "    ct_data = ct_img.get_fdata()\n",
    "\n",
    "    # Apply custom windowing to the CT head image\n",
    "    ct_data_windowed = apply_window(ct_data)\n",
    "\n",
    "    # Plot the images\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(20, 5))\n",
    "    axes[0].imshow(ground_truth_data[:, :, slice_idx], cmap='gray')\n",
    "    axes[1].imshow(prediction_data[:, :, slice_idx], cmap='gray')\n",
    "    axes[2].imshow(ct_data_windowed[:, :, slice_idx], cmap='gray')\n",
    "    axes[3].imshow(ct_data_windowed[:, :, slice_idx], cmap='gray')\n",
    "    axes[3].imshow(ground_truth_data[:, :, slice_idx], cmap='hot', alpha=0.5)\n",
    "    for ax in axes:\n",
    "        ax.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Create widgets for file selection and slice index\n",
    "file_widget = Dropdown(options=file_options)\n",
    "slice_idx_widget = IntSlider(min=0, max=1, step=1, value=0)\n",
    "\n",
    "# Create an interactive plot\n",
    "plot = interactive(plot_images, selected_file=file_widget, slice_idx=slice_idx_widget)\n",
    "\n",
    "# Update the maximum value and value of the slice index slider whenever a new file is selected\n",
    "def update_slice_idx_range(*args):\n",
    "    ct_img = nib.load(os.path.join(ct_images_dir, file_widget.value))\n",
    "    ct_data = ct_img.get_fdata()\n",
    "    slice_idx_widget.max = ct_data.shape[2] - 1\n",
    "    slice_idx_widget.value = min(slice_idx_widget.value, slice_idx_widget.max)\n",
    "\n",
    "file_widget.observe(update_slice_idx_range, 'value')\n",
    "\n",
    "# Manually call the update function to set the initial max value of the slice index slider\n",
    "update_slice_idx_range()\n",
    "\n",
    "# Display the interactive plot\n",
    "display(plot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_list = [x.split(' ')[0] for x in os.listdir('D:\\CTH_archive\\TMAX_NIFTI_QUANT\\REGISTERED')]\n",
    "preds_list = [x.replace('.nii', '') for x in preds_list]\n",
    "CTH_DICOM_SPLIT = [x.split(' ')[0] for x in os.listdir('D:\\CTH_archive\\CTH_DICOM')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_of_interest = set(CTH_DICOM_SPLIT) - set(preds_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_listing = os.listdir(\"D:\\CTH_archive\\CTH_DICOM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering process\n",
    "extracted_paths = []\n",
    "for file_name in directory_listing:\n",
    "    for name in names_of_interest:\n",
    "        if name in file_name:\n",
    "            extracted_paths.append(file_name)\n",
    "            break  # Stop the inner loop once a match is found\n",
    "\n",
    "# Display the extracted file paths\n",
    "for path in extracted_paths:\n",
    "    print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "base_directory = \"D:\\\\CTH_archive\\\\CTH_DICOM\"\n",
    "\n",
    "for path in extracted_paths:\n",
    "    # Construct the full path for the patient directory\n",
    "    patient_directory = os.path.join(base_directory, path)\n",
    "    \n",
    "    # Skip if the path is not a directory (e.g., it's a file like 'BILLIPS_JAMES.nii')\n",
    "    if not os.path.isdir(patient_directory):\n",
    "        continue\n",
    "\n",
    "    # Extract the patient name from the path\n",
    "    patient_name = path.split(' ')[0]  # Assuming patient name is the first part\n",
    "\n",
    "    # Find the last subdirectory within the patient directory, which represents the latest session or date\n",
    "    sessions = [d for d in os.listdir(patient_directory) if os.path.isdir(os.path.join(patient_directory, d))]\n",
    "    sessions.sort()  # Sort to ensure order, in case it's based on date or sequence\n",
    "    if not sessions:  # Check if the list is empty\n",
    "        continue  # Skip if there are no session directories\n",
    "    last_session = sessions[-1]  # Get the last session based on sorted order\n",
    "\n",
    "    # Construct the full path for the last session directory\n",
    "    session_directory = os.path.join(patient_directory, last_session)\n",
    "    \n",
    "    # Specify the output filename using the patient's name\n",
    "    output_file = os.path.join(\"D:\\\\CTH_archive\\\\NIfTI_TEST_SET\", f\"{patient_name}.nii\")\n",
    "    \n",
    "    # Ensure the output directory exists\n",
    "    os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "\n",
    "    # Call the convert_series_to_nifti function for the last session directory\n",
    "    convert_series_to_nifti(session_directory, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pydicom\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def load_dicom_series(directory):\n",
    "    dicom_files = [(os.path.join(directory, f), f) for f in os.listdir(directory) if f.endswith('.dcm')]\n",
    "    dicoms = [(pydicom.dcmread(path), file_name) for path, file_name in dicom_files]\n",
    "    dicoms.sort(key=lambda x: int(x[0].InstanceNumber))\n",
    "    return dicoms\n",
    "\n",
    "def display_image(image, file_name):\n",
    "    clear_output(wait=True)\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.title(file_name)  # Display the file name as the title\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def get_last_subdir(base_path):\n",
    "    # List all the entries in the base path\n",
    "    all_entries = os.listdir(base_path)\n",
    "    \n",
    "    # Filter out files, leaving only directories\n",
    "    dir_entries = [entry for entry in all_entries if os.path.isdir(os.path.join(base_path, entry))]\n",
    "    \n",
    "    # Sort the directories to get the last one\n",
    "    dir_entries.sort()\n",
    "    \n",
    "    # Return the full path of the last subdirectory if available, else return None\n",
    "    return os.path.join(base_path, dir_entries[-1]) if dir_entries else None\n",
    "\n",
    "# Example usage\n",
    "base_path = r\"D:\\CTH_archive\\CTH_DICOM\\TOUATI_MOHAMED 3117292\"\n",
    "dicom_series_directory = get_last_subdir(base_path)\n",
    "\n",
    "dicom_series = load_dicom_series(dicom_series_directory)\n",
    "\n",
    "slider = widgets.IntSlider(value=0, min=0, max=len(dicom_series)-1, step=1, description='Image Index:')\n",
    "\n",
    "def update_image(image_index):\n",
    "    dicom_data, file_name = dicom_series[image_index]\n",
    "    display_image(dicom_data.pixel_array, file_name)\n",
    "\n",
    "widgets.interactive(update_image, image_index=slider)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fx_bounding_box",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
