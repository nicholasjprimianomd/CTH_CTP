{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "from totalsegmentator.python_api import totalsegmentator\n",
    "import os\n",
    "import SimpleITK as sitk\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from image_utils import convert_series_to_nifti, quantize_maps\n",
    "import json\n",
    "import registration_gui as rgui\n",
    "import logging\n",
    "import shutil\n",
    "import random\n",
    "import re\n",
    "from image_utils import ImageVisualizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NUM = \"040\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = r'D:\\CTH_archive\\CTH_NIFTI'\n",
    "stripped_folder = r'D:\\CTH_archive\\CTH_STRIPPED_MASK'\n",
    "output_folder = r'D:\\CTH_archive\\CTH_STRIPPED'\n",
    "\n",
    "# Ensure the stripped and output directories exist\n",
    "os.makedirs(stripped_folder, exist_ok=True)\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Skull stripping process\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.endswith(('.nii')):\n",
    "        patient_name = filename.split(' ')[0]  # Extract patient name\n",
    "        input_path = os.path.join(input_folder, filename)\n",
    "        stripped_path = os.path.join(stripped_folder, patient_name)\n",
    "\n",
    "        # Check if the stripped file already exists\n",
    "        if not os.path.exists(stripped_path):\n",
    "            try:\n",
    "                input_img = nib.load(input_path)\n",
    "                totalsegmentator(input_img, stripped_path, roi_subset=['brain'], ml=True)\n",
    "                print(f\"Processed and saved: {stripped_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {input_path}: {e}\")\n",
    "        else:\n",
    "            print(f\"Stripped file already exists, skipping: {stripped_path}\")\n",
    "\n",
    "# Applying masks to stripped images\n",
    "file_counter = 0  # Initialize file counter\n",
    "missing_files = []\n",
    "\n",
    "for mask_filename in tqdm(os.listdir(stripped_folder)):\n",
    "    base_filename = os.path.splitext(mask_filename)[0].rsplit('.', 1)[0]  # Handle potential double extensions\n",
    "    original_path = None\n",
    "\n",
    "    # Find matching original file\n",
    "    for original_filename in os.listdir(input_folder):\n",
    "        if os.path.splitext(original_filename)[0].rsplit('.', 1)[0] == base_filename:\n",
    "            original_path = os.path.join(input_folder, original_filename)\n",
    "            break\n",
    "\n",
    "    if original_path:\n",
    "        mask_path = os.path.join(stripped_folder, mask_filename)\n",
    "        #output_filename = base_filename + f\"_{file_counter:03d}_0000.nii.gz\"\n",
    "        output_filename = base_filename\n",
    "        output_path = os.path.join(output_folder, output_filename)\n",
    "\n",
    "        # Check if the output file already exists\n",
    "        if not os.path.exists(output_path):\n",
    "            print(f\"Applying mask to {original_path} using {mask_path}\")\n",
    "\n",
    "            # Load and apply mask\n",
    "            mask_nii = nib.load(mask_path)\n",
    "            original_nii = nib.load(original_path)\n",
    "            masked_data = np.where(mask_nii.get_fdata() > 0, original_nii.get_fdata(), 0)\n",
    "            masked_nii = nib.Nifti1Image(masked_data, affine=original_nii.affine)\n",
    "\n",
    "            nib.save(masked_nii, output_path)\n",
    "            file_counter += 1\n",
    "        else:\n",
    "            print(f\"Masked file already exists, skipping: {output_path}\")\n",
    "    else:\n",
    "        print(f\"No matching file found for {mask_filename} in {input_folder}\")\n",
    "        missing_files.append((mask_filename, input_folder))\n",
    "\n",
    "print(\"Mask application complete.\")\n",
    "if missing_files:\n",
    "    print(\"Missing files:\", missing_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms_dir = \"D:/CTH_archive/TRANSFORMS\"\n",
    "fixed_images_dir = \"D:/CTH_archive/CTH_STRIPPED\"  \n",
    "moving_images_dir = \"D:/CTH_archive/CTP_STRIPPED\" \n",
    "\n",
    "def register_images(fixed_image_path, moving_image_path, transforms_dir):\n",
    "    # Extract patient identifier from the file name, ensuring .nii is not included\n",
    "    patient = os.path.splitext(os.path.basename(moving_image_path))[0]\n",
    "    patient = os.path.splitext(patient)[0]  # Remove .nii if present\n",
    "\n",
    "    # Construct the transform file path\n",
    "    transform_file = os.path.join(transforms_dir, f'{patient}.h5')\n",
    "\n",
    "    # Check if the transform file already exists and skip registration if it does\n",
    "    if os.path.exists(transform_file):\n",
    "        print(f\"Transform file already exists for patient {patient}, skipping registration.\")\n",
    "        return\n",
    "\n",
    "    # Load the fixed and moving images\n",
    "    fixed_image = sitk.ReadImage(fixed_image_path)\n",
    "    moving_image = sitk.ReadImage(moving_image_path)\n",
    "\n",
    "    # Initialize the registration method\n",
    "    registration_method = sitk.ImageRegistrationMethod()\n",
    "    registration_method.SetMetricAsMattesMutualInformation(numberOfHistogramBins=50)\n",
    "    registration_method.SetMetricSamplingPercentage(0.10)\n",
    "    registration_method.SetMetricSamplingStrategy(registration_method.RANDOM)\n",
    "    registration_method.SetOptimizerAsGradientDescentLineSearch(learningRate=0.5, numberOfIterations=200)\n",
    "    registration_method.SetOptimizerScalesFromPhysicalShift()\n",
    "    registration_method.SetShrinkFactorsPerLevel(shrinkFactors=[8, 4, 2])\n",
    "    registration_method.SetSmoothingSigmasPerLevel(smoothingSigmas=[4, 2, 1])\n",
    "    registration_method.SmoothingSigmasAreSpecifiedInPhysicalUnitsOn()\n",
    "\n",
    "    # Initialize the transform\n",
    "    initial_transform = sitk.CenteredTransformInitializer(sitk.Cast(fixed_image, moving_image.GetPixelID()), \n",
    "                                                          moving_image, \n",
    "                                                          sitk.AffineTransform(fixed_image.GetDimension()),\n",
    "                                                          sitk.CenteredTransformInitializerFilter.GEOMETRY)\n",
    "    registration_method.SetInitialTransform(initial_transform, True)\n",
    "\n",
    "    try:\n",
    "        # Execute the registration\n",
    "        final_transform = registration_method.Execute(fixed_image, moving_image)\n",
    "        \n",
    "        # Save the transform\n",
    "        sitk.WriteTransform(final_transform, transform_file)\n",
    "        sitk.WriteImage(sitk.Resample(moving_image, fixed_image, final_transform,  sitk.sitkNearestNeighbor), f\"D:/CTH_archive/CTP_STRIPPED_REG/{patient}.nii\")\n",
    "        print(\"Final metric value: {0}\".format(registration_method.GetMetricValue()))\n",
    "        print(\n",
    "            \"Optimizer's stopping condition, {0}\".format(\n",
    "                registration_method.GetOptimizerStopConditionDescription()\n",
    "            )\n",
    "        )\n",
    "        print(f\"Registration successful for patient: {patient}. Transform saved to {transform_file}\")\n",
    "    except RuntimeError as e:\n",
    "        print(f\"Registration failed for patient {patient}: {e}\")\n",
    "\n",
    "\n",
    "for filename in tqdm(os.listdir(fixed_images_dir)):\n",
    "    fixed_image_path = os.path.join(fixed_images_dir, filename)\n",
    "    moving_image_path = os.path.join(moving_images_dir, filename)\n",
    "\n",
    "    if os.path.isfile(fixed_image_path) and os.path.isfile(moving_image_path):\n",
    "        register_images(fixed_image_path, moving_image_path, transforms_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FINAL_SIZE = 512\n",
    "\n",
    "def resample_image(moving_image, ctp_image):\n",
    "    desired_size = [FINAL_SIZE, FINAL_SIZE, ctp_image.GetSize()[2]] # Use the same number of slices as the CTP image\n",
    "    resampler = sitk.ResampleImageFilter()\n",
    "    resampler.SetReferenceImage(moving_image)\n",
    "    resampler.SetSize(desired_size)\n",
    "    resampler.SetOutputSpacing([moving_image.GetSpacing()[i] * (moving_image.GetSize()[i] / desired_size[i]) for i in range(3)]) \n",
    "    resampler.SetInterpolator(sitk.sitkLinear)\n",
    "    resized_moving_image = resampler.Execute(moving_image)\n",
    "    resized_moving_image.SetSpacing(ctp_image.GetSpacing())\n",
    "    resized_moving_image.SetOrigin(ctp_image.GetOrigin())\n",
    "    resized_moving_image.SetDirection(ctp_image.GetDirection())\n",
    "    return resized_moving_image\n",
    "\n",
    "def apply_final_transform(resized_moving_image, fixed_image, transform_file_path):\n",
    "    final_transform = sitk.ReadTransform(transform_file_path)\n",
    "    resampled_image = sitk.Resample(resized_moving_image, \n",
    "                                    fixed_image, \n",
    "                                    final_transform, \n",
    "                                    sitk.sitkNearestNeighbor, \n",
    "                                    0.0, \n",
    "                                    fixed_image.GetPixelID())\n",
    "    return resampled_image\n",
    "\n",
    "def apply_final_transform(resized_moving_image, fixed_image, transform_file_path):\n",
    "    try:\n",
    "        final_transform = sitk.ReadTransform(transform_file_path)\n",
    "        \n",
    "        # Ensure the resized_moving_image is valid before proceeding\n",
    "        if resized_moving_image:\n",
    "            resampled_image = sitk.Resample(resized_moving_image, \n",
    "                                            fixed_image, \n",
    "                                            final_transform, \n",
    "                                            sitk.sitkLinear, \n",
    "                                            0.0, \n",
    "                                            fixed_image.GetPixelID())\n",
    "            return resampled_image\n",
    "        else:\n",
    "            logging.error(\"Resized moving image is invalid. Cannot apply final transform.\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        logging.error(\"Failed to apply final transform: \" + str(e))\n",
    "        return None\n",
    "\n",
    "tmax_nifti_dir = r\"D:/CTH_archive/TMAX_NIFTI\"\n",
    "transforms_dir = r\"D:/CTH_archive/TRANSFORMS\"\n",
    "cth_stripped_dir = r\"D:/CTH_archive/CTH_STRIPPED\"\n",
    "ctp_stripped_dir = r\"D:/CTH_archive/CTP_STRIPPED\"\n",
    "output_dir = r'D:/CTH_archive/TMAX_REGISTERED'\n",
    "\n",
    "# Ensure the output directory exists\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Iterate over the transformation files\n",
    "for transform_file in os.listdir(transforms_dir):\n",
    "    transform_path = os.path.join(transforms_dir, transform_file)\n",
    "    base_filename = transform_file.replace('.h5', '')\n",
    "\n",
    "    # Paths to the moving, fixed, and reference (ctp) images\n",
    "    moving_image_path = os.path.join(tmax_nifti_dir, base_filename + '.nii')\n",
    "    fixed_image_path = os.path.join(cth_stripped_dir, base_filename + '.nii')\n",
    "    ctp_image_path = os.path.join(ctp_stripped_dir, base_filename + '.nii')\n",
    "    print(f\"Processing {base_filename}...\")\n",
    "\n",
    "    # Check if all required files exist\n",
    "    if os.path.exists(moving_image_path) and os.path.exists(fixed_image_path) and os.path.exists(ctp_image_path):\n",
    "        # Load images\n",
    "        moving_image = sitk.ReadImage(moving_image_path)\n",
    "        fixed_image = sitk.ReadImage(fixed_image_path)\n",
    "        ctp_image = sitk.ReadImage(ctp_image_path)\n",
    "\n",
    "        # Resample the moving image\n",
    "        resized_moving_image = resample_image(moving_image, ctp_image)\n",
    "\n",
    "        # Apply the final transformation\n",
    "        resampled_image = apply_final_transform(resized_moving_image, fixed_image, transform_path)\n",
    "\n",
    "        # Save the resampled image\n",
    "        resampled_image_path = os.path.join(output_dir, base_filename + '.nii')\n",
    "        sitk.WriteImage(resampled_image, resampled_image_path)\n",
    "        print(f\"Processed and saved: {resampled_image_path}\")\n",
    "    else:\n",
    "        print(f\"Required files for {base_filename} are not available.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TMAX_SOURCE_DIR = r'D:\\\\CTH_archive\\\\TMAX_REGISTERED\\\\'\n",
    "TMAX_QUNTIZED_DIR = r'D:\\\\CTH_archive\\\\TMAX_NIFTI_QUANT_REGISTERED'\n",
    "\n",
    "quantization_levels = 5\n",
    "\n",
    "quantize_maps(TMAX_SOURCE_DIR, TMAX_QUNTIZED_DIR, quantization_levels=quantization_levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_test_files = 5\n",
    "\n",
    "def convert_and_copy_with_labels_and_rename(image_source_dir, image_target_dir, label_source_dir, label_target_dir, images_test_dir, labels_test_dir):\n",
    "    # Ensure all target directories exist, create if they don't\n",
    "    for dir_path in [image_target_dir, label_target_dir, images_test_dir, labels_test_dir]:\n",
    "        if not os.path.exists(dir_path):\n",
    "            os.makedirs(dir_path)\n",
    "\n",
    "    # List all .nii files in the source directory\n",
    "    all_files = [f for f in sorted(os.listdir(image_source_dir)) if f.endswith('.nii')]\n",
    "    \n",
    "    # Determine the number of files to sample, ensuring it's not more than the total number of files available\n",
    "    num_test_files = min(5, len(all_files))\n",
    "\n",
    "    # Randomly select files for testing, based on the determined number\n",
    "    test_files = random.sample(all_files, num_test_files)\n",
    "\n",
    "    counter = 0\n",
    "\n",
    "    # Move selected test files and their labels\n",
    "    for file_name in tqdm(test_files, desc=\"Moving test files\"):\n",
    "        # Extract base name without extension and trailing numbers\n",
    "        base_name = re.match(r\"(.*?)(?:_\\d+)?(?=\\.\\w+$)\", file_name).group(1)\n",
    "        \n",
    "        # Increment the counter\n",
    "        counter += 1\n",
    "\n",
    "        # Construct new file names with suffixes\n",
    "        new_image_name = f\"{base_name}_{counter:03d}_0000.nii.gz\"\n",
    "        new_label_name = f\"{base_name}_{counter:03d}.nii.gz\"\n",
    "        \n",
    "        # Copy the image file with the new name\n",
    "        shutil.copy(os.path.join(image_source_dir, file_name), os.path.join(images_test_dir, new_image_name))\n",
    "        \n",
    "        # Adjust the file name for the label to match the source\n",
    "        label_file_name = file_name.replace('.nii.gz', '.nii') if file_name.endswith('.nii.gz') else file_name\n",
    "        \n",
    "        # Copy the label file with the new name\n",
    "        shutil.copy(os.path.join(label_source_dir, label_file_name), os.path.join(labels_test_dir, new_label_name))\n",
    "        \n",
    "        print(f\"Moved {file_name} and its label to the test directories with new names: {new_image_name} and {new_label_name}\")\n",
    "\n",
    "    # Remove test files from the all_files list\n",
    "    for test_file in test_files:\n",
    "        all_files.remove(test_file)\n",
    "\n",
    "    # Initialize a counter for unique naming within the training set\n",
    "    counter = 0\n",
    "\n",
    "    # Iterate over the remaining files for training\n",
    "    for file_name in tqdm(all_files, desc=\"Processing training files\"):\n",
    "        # Construct full source file paths for images and labels\n",
    "        image_source_file_path = os.path.join(image_source_dir, file_name)\n",
    "        label_source_file_path = os.path.join(label_source_dir, file_name)\n",
    "\n",
    "        # Load the .nii file (image)\n",
    "        nii_image = nib.load(image_source_file_path)\n",
    "\n",
    "        # Construct the new file name for images and labels\n",
    "        base_name = file_name[:-4]  # Remove .nii extension\n",
    "        new_image_name = f\"{base_name}_{counter:03d}_0000.nii.gz\"\n",
    "        new_label_name = f\"{base_name}_{counter:03d}.nii.gz\"\n",
    "\n",
    "        # Construct target file paths\n",
    "        image_target_file_path = os.path.join(image_target_dir, new_image_name)\n",
    "        label_target_file_path = os.path.join(label_target_dir, new_label_name)\n",
    "\n",
    "        # Save the image file as .nii.gz in the target directory\n",
    "        nib.save(nii_image, image_target_file_path)\n",
    "        print(f\"Converted and copied image: {image_source_file_path} to {image_target_file_path}\")\n",
    "\n",
    "        # Load the .nii file (label)\n",
    "        nii_label = nib.load(label_source_file_path)\n",
    "\n",
    "        # Save the label file as .nii.gz in the target directory\n",
    "        nib.save(nii_label, label_target_file_path)\n",
    "        print(f\"Converted and copied label: {label_source_file_path} to {label_target_file_path}\")\n",
    "\n",
    "        # Increment the counter for unique naming\n",
    "        counter += 1\n",
    "\n",
    "# Define source and target directories for images and labels\n",
    "image_source_dir = rf\"D:/CTH_archive/CTH_STRIPPED\"\n",
    "image_target_dir = rf\"D:/nnUNet_raw/Dataset{DATASET_NUM}_Perfusion/imagesTr\"\n",
    "label_source_dir = rf\"D:/CTH_archive/TMAX_NIFTI_QUANT_REGISTERED\"\n",
    "label_target_dir = rf\"D:/nnUNet_raw/Dataset{DATASET_NUM}_Perfusion/labelsTr\"\n",
    "\n",
    "# Define target directories for testing\n",
    "images_test_dir = rf\"D:/nnUNet_raw/Dataset{DATASET_NUM}_Perfusion/imagesTs\"\n",
    "labels_test_dir = rf\"D:/nnUNet_raw/Dataset{DATASET_NUM}_Perfusion/labelsTs\"\n",
    "\n",
    "convert_and_copy_with_labels_and_rename(image_source_dir, image_target_dir, label_source_dir, label_target_dir, images_test_dir, labels_test_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset_json(dataset_dir, num_quant_levels, channel_names, nnUNet_dir, file_ending=\".nii.gz\", num_test_data=0):\n",
    "    \"\"\"\n",
    "    Generate a dataset.json file for the given dataset with dynamic quantization levels.\n",
    "\n",
    "    Args:\n",
    "    - dataset_dir (str): Directory where the dataset files are stored.\n",
    "    - num_quant_levels (int): Number of quantization levels (excluding the background).\n",
    "    - channel_names (dict): Mapping of channel indices to their names.\n",
    "    - file_ending (str): File extension of the dataset files.\n",
    "    - num_test_data (int): The number of the dataset to be used for testing.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    # Dynamically generate labels based on the number of quantization levels\n",
    "    labels = {\"background\": \"0\"}\n",
    "    for i in range(1, num_quant_levels + 1):\n",
    "        labels[f\"quantized_{i}\"] = str(i)\n",
    "\n",
    "    # Count the number of dataset files\n",
    "    num_training = len([file for file in os.listdir(dataset_dir) if file.endswith(file_ending)])\n",
    "\n",
    "    # Use the specified number of test data and calculate the remaining number of training files\n",
    "    num_test = num_test_data\n",
    "\n",
    "    # Construct the dataset JSON structure\n",
    "    dataset_json = {\n",
    "        \"labels\": labels,\n",
    "        \"numTraining\": num_training,\n",
    "        \"numTest\": num_test,\n",
    "        \"channel_names\": channel_names,\n",
    "        \"file_ending\": file_ending\n",
    "    }\n",
    "\n",
    "    # Write the JSON structure to a file\n",
    "    with open(os.path.join(nnUNet_dir, \"dataset.json\"), 'w') as json_file:\n",
    "        json.dump(dataset_json, json_file, indent=4)\n",
    "\n",
    "    print(f\"dataset.json file has been generated in {nnUNet_dir}\")\n",
    "\n",
    "# Example usage\n",
    "dataset_dir = rf'D:\\nnUNet_raw\\Dataset{DATASET_NUM}_Perfusion\\labelsTr'  # Path to dataset directory\n",
    "nnUNet_dir = rf'D:\\nnUNet_raw\\Dataset{DATASET_NUM}_Perfusion'  # Path to nnUNet directory\n",
    "num_quant_levels = 5  # Number of quantization levels (excluding background)\n",
    "channel_names = {\"0\": \"CT\"}\n",
    "num_test_data = 5  # Specify the number of test data\n",
    "\n",
    "generate_dataset_json(dataset_dir, num_quant_levels, channel_names, nnUNet_dir, file_ending=\".nii.gz\", num_test_data=num_test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nnuNetv2_plan_and_preprocess -d $DATASET_NUM --verify_dataset_integrity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nnUNetv2_train $DATASET_NUM 3d_fullres 0 --npz -device cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nnUNetv2_predict -d Dataset_{DATASET_NUM}_Perfusion -i  D:\\nnUNet_raw\\Dataset_{DATASET_NUM}Perfusion\\imagesTs -o D:\\nnUNet_output\\Dataset{DATAST_NUM}Perfusion -f  0 -tr nnUNetTrainer -c 3d_fullres -p nnUNetPlans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from image_utils import ImageVisualizer\n",
    "\n",
    "prediction_dir = rf\"D:\\nnUnet_output\\Dataset{DATASET_NUM}_Perfusion\"\n",
    "ground_truth_dir = rf\"D:\\nnUNet_raw\\Dataset{DATASET_NUM}_Perfusion\\labelsTs\"\n",
    "ct_images_dir = r\"D:\\CTH_archive\\CTH_STRIPPED\"\n",
    "\n",
    "visualizer = ImageVisualizer(prediction_dir, ground_truth_dir, ct_images_dir)\n",
    "visualizer.display()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fx_bounding_box",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
