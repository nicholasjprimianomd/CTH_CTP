{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "from totalsegmentator.python_api import totalsegmentator\n",
    "import os\n",
    "import SimpleITK as sitk\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from image_utils import convert_series_to_nifti, quantize_maps\n",
    "%matplotlib widget\n",
    "import gui\n",
    "import json\n",
    "import registration_gui as rgui\n",
    "import logging\n",
    "import shutil\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = r'D:\\CTH_archive\\CTH_NIFTI'\n",
    "stripped_folder = r'D:\\CTH_archive\\CTH_STRIPPED_MASK'\n",
    "output_folder = r'D:\\CTH_archive\\CTH_STRIPPED'\n",
    "\n",
    "# Ensure the stripped and output directories exist\n",
    "os.makedirs(stripped_folder, exist_ok=True)\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Skull stripping process\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.endswith(('.nii')):\n",
    "        patient_name = filename.split(' ')[0]  # Extract patient name\n",
    "        input_path = os.path.join(input_folder, filename)\n",
    "        stripped_path = os.path.join(stripped_folder, patient_name)\n",
    "\n",
    "        # Check if the stripped file already exists\n",
    "        if not os.path.exists(stripped_path):\n",
    "            try:\n",
    "                input_img = nib.load(input_path)\n",
    "                totalsegmentator(input_img, stripped_path, roi_subset=['brain'], ml=True)\n",
    "                print(f\"Processed and saved: {stripped_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {input_path}: {e}\")\n",
    "        else:\n",
    "            print(f\"Stripped file already exists, skipping: {stripped_path}\")\n",
    "\n",
    "# Applying masks to stripped images\n",
    "file_counter = 0  # Initialize file counter\n",
    "missing_files = []\n",
    "\n",
    "for mask_filename in tqdm(os.listdir(stripped_folder)):\n",
    "    base_filename = os.path.splitext(mask_filename)[0].rsplit('.', 1)[0]  # Handle potential double extensions\n",
    "    original_path = None\n",
    "\n",
    "    # Find matching original file\n",
    "    for original_filename in os.listdir(input_folder):\n",
    "        if os.path.splitext(original_filename)[0].rsplit('.', 1)[0] == base_filename:\n",
    "            original_path = os.path.join(input_folder, original_filename)\n",
    "            break\n",
    "\n",
    "    if original_path:\n",
    "        mask_path = os.path.join(stripped_folder, mask_filename)\n",
    "        #output_filename = base_filename + f\"_{file_counter:03d}_0000.nii.gz\"\n",
    "        output_filename = base_filename\n",
    "        output_path = os.path.join(output_folder, output_filename)\n",
    "\n",
    "        # Check if the output file already exists\n",
    "        if not os.path.exists(output_path):\n",
    "            print(f\"Applying mask to {original_path} using {mask_path}\")\n",
    "\n",
    "            # Load and apply mask\n",
    "            mask_nii = nib.load(mask_path)\n",
    "            original_nii = nib.load(original_path)\n",
    "            masked_data = np.where(mask_nii.get_fdata() > 0, original_nii.get_fdata(), 0)\n",
    "            masked_nii = nib.Nifti1Image(masked_data, affine=original_nii.affine)\n",
    "\n",
    "            nib.save(masked_nii, output_path)\n",
    "            file_counter += 1\n",
    "        else:\n",
    "            print(f\"Masked file already exists, skipping: {output_path}\")\n",
    "    else:\n",
    "        print(f\"No matching file found for {mask_filename} in {input_folder}\")\n",
    "        missing_files.append((mask_filename, input_folder))\n",
    "\n",
    "print(\"Mask application complete.\")\n",
    "if missing_files:\n",
    "    print(\"Missing files:\", missing_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms_dir = \"D:/CTH_archive/TRANSFORMS\"\n",
    "fixed_images_dir = \"D:/CTH_archive/CTH_STRIPPED\"  \n",
    "moving_images_dir = \"D:/CTH_archive/CTP_STRIPPED\" \n",
    "\n",
    "def register_images(fixed_image_path, moving_image_path, transforms_dir):\n",
    "    # Extract patient identifier from the file name, ensuring .nii is not included\n",
    "    patient = os.path.splitext(os.path.basename(moving_image_path))[0]\n",
    "    patient = os.path.splitext(patient)[0]  # Remove .nii if present\n",
    "\n",
    "    # Construct the transform file path\n",
    "    transform_file = os.path.join(transforms_dir, f'{patient}.h5')\n",
    "\n",
    "    # Check if the transform file already exists and skip registration if it does\n",
    "    if os.path.exists(transform_file):\n",
    "        print(f\"Transform file already exists for patient {patient}, skipping registration.\")\n",
    "        return\n",
    "\n",
    "    # Load the fixed and moving images\n",
    "    fixed_image = sitk.ReadImage(fixed_image_path)\n",
    "    moving_image = sitk.ReadImage(moving_image_path)\n",
    "\n",
    "    # Initialize the registration method\n",
    "    registration_method = sitk.ImageRegistrationMethod()\n",
    "    registration_method.SetMetricAsMattesMutualInformation(numberOfHistogramBins=50)\n",
    "    registration_method.SetMetricSamplingPercentage(0.10)\n",
    "    registration_method.SetMetricSamplingStrategy(registration_method.RANDOM)\n",
    "    registration_method.SetOptimizerAsGradientDescentLineSearch(learningRate=0.5, numberOfIterations=200)\n",
    "    registration_method.SetOptimizerScalesFromPhysicalShift()\n",
    "    registration_method.SetShrinkFactorsPerLevel(shrinkFactors=[8, 4, 2])\n",
    "    registration_method.SetSmoothingSigmasPerLevel(smoothingSigmas=[4, 2, 1])\n",
    "    registration_method.SmoothingSigmasAreSpecifiedInPhysicalUnitsOn()\n",
    "\n",
    "    # Initialize the transform\n",
    "    initial_transform = sitk.CenteredTransformInitializer(sitk.Cast(fixed_image, moving_image.GetPixelID()), \n",
    "                                                          moving_image, \n",
    "                                                          sitk.AffineTransform(fixed_image.GetDimension()),\n",
    "                                                          sitk.CenteredTransformInitializerFilter.GEOMETRY)\n",
    "    registration_method.SetInitialTransform(initial_transform, True)\n",
    "\n",
    "    try:\n",
    "        # Execute the registration\n",
    "        final_transform = registration_method.Execute(fixed_image, moving_image)\n",
    "        \n",
    "        # Save the transform\n",
    "        sitk.WriteTransform(final_transform, transform_file)\n",
    "        sitk.WriteImage(sitk.Resample(moving_image, fixed_image, final_transform,  sitk.sitkNearestNeighbor), f\"D:/CTH_archive/CTP_STRIPPED_REG/{patient}.nii\")\n",
    "        print(\"Final metric value: {0}\".format(registration_method.GetMetricValue()))\n",
    "        print(\n",
    "            \"Optimizer's stopping condition, {0}\".format(\n",
    "                registration_method.GetOptimizerStopConditionDescription()\n",
    "            )\n",
    "        )\n",
    "        print(f\"Registration successful for patient: {patient}. Transform saved to {transform_file}\")\n",
    "    except RuntimeError as e:\n",
    "        print(f\"Registration failed for patient {patient}: {e}\")\n",
    "\n",
    "\n",
    "for filename in tqdm(os.listdir(fixed_images_dir)):\n",
    "    fixed_image_path = os.path.join(fixed_images_dir, filename)\n",
    "    moving_image_path = os.path.join(moving_images_dir, filename)\n",
    "\n",
    "    if os.path.isfile(fixed_image_path) and os.path.isfile(moving_image_path):\n",
    "        register_images(fixed_image_path, moving_image_path, transforms_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FINAL_SIZE = 512\n",
    "\n",
    "def resample_image(moving_image, fixed_image, ctp_image):\n",
    "    desired_size = [FINAL_SIZE, FINAL_SIZE, ctp_image.GetSize()[2]] # Use the same number of slices as the CTP image\n",
    "    resampler = sitk.ResampleImageFilter()\n",
    "    resampler.SetReferenceImage(moving_image)\n",
    "    resampler.SetSize(desired_size)\n",
    "    resampler.SetOutputSpacing([moving_image.GetSpacing()[i] * (moving_image.GetSize()[i] / desired_size[i]) for i in range(3)]) \n",
    "    resampler.SetInterpolator(sitk.sitkLinear)\n",
    "    resized_moving_image = resampler.Execute(moving_image)\n",
    "    resized_moving_image.SetSpacing(ctp_image.GetSpacing())\n",
    "    resized_moving_image.SetOrigin(ctp_image.GetOrigin())\n",
    "    resized_moving_image.SetDirection(ctp_image.GetDirection())\n",
    "    return resized_moving_image\n",
    "\n",
    "def apply_final_transform(resized_moving_image, fixed_image, transform_file_path):\n",
    "    final_transform = sitk.ReadTransform(transform_file_path)\n",
    "    resampled_image = sitk.Resample(resized_moving_image, \n",
    "                                    fixed_image, \n",
    "                                    final_transform, \n",
    "                                    sitk.sitkNearestNeighbor, \n",
    "                                    0.0, \n",
    "                                    fixed_image.GetPixelID())\n",
    "    return resampled_image\n",
    "\n",
    "def apply_final_transform(resized_moving_image, fixed_image, transform_file_path):\n",
    "    try:\n",
    "        final_transform = sitk.ReadTransform(transform_file_path)\n",
    "        \n",
    "        # Ensure the resized_moving_image is valid before proceeding\n",
    "        if resized_moving_image:\n",
    "            resampled_image = sitk.Resample(resized_moving_image, \n",
    "                                            fixed_image, \n",
    "                                            final_transform, \n",
    "                                            sitk.sitkLinear, \n",
    "                                            0.0, \n",
    "                                            fixed_image.GetPixelID())\n",
    "            return resampled_image\n",
    "        else:\n",
    "            logging.error(\"Resized moving image is invalid. Cannot apply final transform.\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        logging.error(\"Failed to apply final transform: \" + str(e))\n",
    "        return None\n",
    "\n",
    "tmax_nifti_dir = r\"D:/CTH_archive/TMAX_NIFTI\"\n",
    "transforms_dir = r\"D:/CTH_archive/TRANSFORMS\"\n",
    "cth_stripped_dir = r\"D:/CTH_archive/CTH_STRIPPED\"\n",
    "ctp_stripped_dir = r\"D:/CTH_archive/CTP_STRIPPED\"\n",
    "output_dir = r'D:/CTH_archive/TMAX_REGISTERED'\n",
    "\n",
    "# Ensure the output directory exists\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Iterate over the transformation files\n",
    "for transform_file in os.listdir(transforms_dir):\n",
    "    transform_path = os.path.join(transforms_dir, transform_file)\n",
    "    base_filename = transform_file.replace('.h5', '')\n",
    "\n",
    "    # Paths to the moving, fixed, and reference (ctp) images\n",
    "    moving_image_path = os.path.join(tmax_nifti_dir, base_filename + '.nii')\n",
    "    fixed_image_path = os.path.join(cth_stripped_dir, base_filename + '.nii')\n",
    "    ctp_image_path = os.path.join(ctp_stripped_dir, base_filename + '.nii')\n",
    "    print(f\"Processing {base_filename}...\")\n",
    "\n",
    "    # Check if all required files exist\n",
    "    if os.path.exists(moving_image_path) and os.path.exists(fixed_image_path) and os.path.exists(ctp_image_path):\n",
    "        # Load images\n",
    "        moving_image = sitk.ReadImage(moving_image_path)\n",
    "        fixed_image = sitk.ReadImage(fixed_image_path)\n",
    "        ctp_image = sitk.ReadImage(ctp_image_path)\n",
    "\n",
    "        # Resample the moving image\n",
    "        resized_moving_image = resample_image(moving_image, fixed_image, ctp_image)\n",
    "\n",
    "        # Apply the final transformation\n",
    "        resampled_image = apply_final_transform(resized_moving_image, fixed_image, transform_path)\n",
    "\n",
    "        # Save the resampled image\n",
    "        resampled_image_path = os.path.join(output_dir, base_filename + '.nii')\n",
    "        sitk.WriteImage(resampled_image, resampled_image_path)\n",
    "        print(f\"Processed and saved: {resampled_image_path}\")\n",
    "    else:\n",
    "        print(f\"Required files for {base_filename} are not available.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TMAX_SOURCE_DIR = r'D:\\\\CTH_archive\\\\TMAX_REGISTERED\\\\'\n",
    "TMAX_QUNTIZED_DIR = r'D:\\\\CTH_archive\\\\TMAX_NIFTI_QUANT_REGISTERED'\n",
    "\n",
    "quantization_levels = 5\n",
    "\n",
    "quantize_maps(TMAX_SOURCE_DIR, TMAX_QUNTIZED_DIR, quantization_levels=quantization_levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_test_files = 5\n",
    "\n",
    "def convert_and_copy_with_labels_and_rename(image_source_dir, image_target_dir, label_source_dir, label_target_dir, images_test_dir, labels_test_dir):\n",
    "    # Ensure all target directories exist, create if they don't\n",
    "    for dir_path in [image_target_dir, label_target_dir, images_test_dir, labels_test_dir]:\n",
    "        if not os.path.exists(dir_path):\n",
    "            os.makedirs(dir_path)\n",
    "\n",
    "    # List all .nii files in the source directory\n",
    "    all_files = [f for f in sorted(os.listdir(image_source_dir)) if f.endswith('.nii')]\n",
    "    \n",
    "    # Determine the number of files to sample, ensuring it's not more than the total number of files available\n",
    "    num_test_files = min(5, len(all_files))\n",
    "\n",
    "    # Randomly select files for testing, based on the determined number\n",
    "    test_files = random.sample(all_files, num_test_files)\n",
    "\n",
    "    # Move selected test files and their labels\n",
    "    for file_name in tqdm(test_files, desc=\"Moving test files\"):\n",
    "        shutil.copy(os.path.join(image_source_dir, file_name), os.path.join(images_test_dir, file_name))\n",
    "        \n",
    "        # Adjust the file name for the label to match the .nii extension\n",
    "        label_file_name = file_name.replace('.nii.gz', '.nii') if file_name.endswith('.nii.gz') else file_name\n",
    "        shutil.copy(os.path.join(label_source_dir, label_file_name), os.path.join(labels_test_dir, label_file_name))\n",
    "        print(f\"Moved {file_name} and its label to the test directories.\")\n",
    "\n",
    "    # Remove test files from the all_files list\n",
    "    for test_file in test_files:\n",
    "        all_files.remove(test_file)\n",
    "\n",
    "    # Initialize a counter for unique naming within the training set\n",
    "    counter = 0\n",
    "\n",
    "    # Iterate over the remaining files for training\n",
    "    for file_name in tqdm(all_files, desc=\"Processing training files\"):\n",
    "        # Construct full source file paths for images and labels\n",
    "        image_source_file_path = os.path.join(image_source_dir, file_name)\n",
    "        label_source_file_path = os.path.join(label_source_dir, file_name)\n",
    "\n",
    "        # Load the .nii file (image)\n",
    "        nii_image = nib.load(image_source_file_path)\n",
    "\n",
    "        # Construct the new file name for images and labels\n",
    "        base_name = file_name[:-4]  # Remove .nii extension\n",
    "        new_image_name = f\"{base_name}_{counter:03d}_0000.nii.gz\"\n",
    "        new_label_name = f\"{base_name}_{counter:03d}.nii.gz\"\n",
    "\n",
    "        # Construct target file paths\n",
    "        image_target_file_path = os.path.join(image_target_dir, new_image_name)\n",
    "        label_target_file_path = os.path.join(label_target_dir, new_label_name)\n",
    "\n",
    "        # Save the image file as .nii.gz in the target directory\n",
    "        nib.save(nii_image, image_target_file_path)\n",
    "        print(f\"Converted and copied image: {image_source_file_path} to {image_target_file_path}\")\n",
    "\n",
    "        # Load the .nii file (label)\n",
    "        nii_label = nib.load(label_source_file_path)\n",
    "\n",
    "        # Save the label file as .nii.gz in the target directory\n",
    "        nib.save(nii_label, label_target_file_path)\n",
    "        print(f\"Converted and copied label: {label_source_file_path} to {label_target_file_path}\")\n",
    "\n",
    "        # Increment the counter for unique naming\n",
    "        counter += 1\n",
    "\n",
    "# Define source and target directories for images and labels\n",
    "image_source_dir = r\"D:/CTH_archive/CTH_STRIPPED\"\n",
    "image_target_dir = r\"D:/nnUNet_raw/Dataset039_Perfusion/imagesTr\"\n",
    "label_source_dir = r\"D:/CTH_archive/TMAX_NIFTI_QUANT_REGISTERED\"\n",
    "label_target_dir = r\"D:/nnUNet_raw/Dataset039_Perfusion/labelsTr\"\n",
    "\n",
    "# Define target directories for testing\n",
    "images_test_dir = r\"D:/nnUNet_raw/Dataset039_Perfusion/imagesTs\"\n",
    "labels_test_dir = r\"D:/nnUNet_raw/Dataset039_Perfusion/labelsTs\"\n",
    "\n",
    "convert_and_copy_with_labels_and_rename(image_source_dir, image_target_dir, label_source_dir, label_target_dir, images_test_dir, labels_test_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset_json(dataset_dir, num_quant_levels, channel_names, nnUNet_dir, file_ending=\".nii.gz\", num_test_data=0):\n",
    "    \"\"\"\n",
    "    Generate a dataset.json file for the given dataset with dynamic quantization levels.\n",
    "\n",
    "    Args:\n",
    "    - dataset_dir (str): Directory where the dataset files are stored.\n",
    "    - num_quant_levels (int): Number of quantization levels (excluding the background).\n",
    "    - channel_names (dict): Mapping of channel indices to their names.\n",
    "    - file_ending (str): File extension of the dataset files.\n",
    "    - num_test_data (int): The number of the dataset to be used for testing.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    # Dynamically generate labels based on the number of quantization levels\n",
    "    labels = {\"background\": \"0\"}\n",
    "    for i in range(1, num_quant_levels + 1):\n",
    "        labels[f\"quantized_{i}\"] = str(i)\n",
    "\n",
    "    # Count the number of dataset files\n",
    "    num_training = len([file for file in os.listdir(dataset_dir) if file.endswith(file_ending)])\n",
    "\n",
    "    # Use the specified number of test data and calculate the remaining number of training files\n",
    "    num_test = num_test_data\n",
    "\n",
    "    # Construct the dataset JSON structure\n",
    "    dataset_json = {\n",
    "        \"labels\": labels,\n",
    "        \"numTraining\": num_training,\n",
    "        \"numTest\": num_test,\n",
    "        \"channel_names\": channel_names,\n",
    "        \"file_ending\": file_ending\n",
    "    }\n",
    "\n",
    "    # Write the JSON structure to a file\n",
    "    with open(os.path.join(nnUNet_dir, \"dataset.json\"), 'w') as json_file:\n",
    "        json.dump(dataset_json, json_file, indent=4)\n",
    "\n",
    "    print(f\"dataset.json file has been generated in {nnUNet_dir}\")\n",
    "\n",
    "# Example usage\n",
    "dataset_dir = r'D:\\nnUNet_raw\\Dataset039_Perfusion\\labelsTr'  # Path to dataset directory\n",
    "nnUNet_dir = r'D:\\nnUNet_raw\\Dataset039_Perfusion'  # Path to nnUNet directory\n",
    "num_quant_levels = 5  # Number of quantization levels (excluding background)\n",
    "channel_names = {\"0\": \"CT\"}\n",
    "num_test_data = 5  # Specify the number of test data\n",
    "\n",
    "generate_dataset_json(dataset_dir, num_quant_levels, channel_names, nnUNet_dir, file_ending=\".nii.gz\", num_test_data=num_test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa30106f28d74b4ab95b2ad910b2763f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Dropdown(options=('ALFORD_BARBARA.nii', 'ALLAH_MAJUSTICE.nii', 'BATTLE_MARIA.nii', 'BAUM_ROBERTâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from image_utils import ImageVisualizer\n",
    "\n",
    "prediction_dir = r\"D:\\CTH_archive\\CTP_STRIPPED\"\n",
    "ground_truth_dir = r\"D:\\CTH_archive\\TMAX_NIFTI_QUANT_REGISTERED\"\n",
    "ct_images_dir = r\"D:\\CTH_archive\\CTH_NIFTI\"\n",
    "\n",
    "visualizer = ImageVisualizer(prediction_dir, ground_truth_dir, ct_images_dir)\n",
    "visualizer.display()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import Dropdown, IntSlider, interactive\n",
    "from IPython.display import display\n",
    "\n",
    "# Directories\n",
    "prediction_dir = r\"D:\\CTH_archive\\CTP_STRIPPED\"\n",
    "ground_truth_dir = r\"D:\\CTH_archive\\TMAX_NIFTI_QUANT_REGISTERED\"\n",
    "ct_images_dir = r\"D:\\CTH_archive\\CTH_NIFTI\"\n",
    "\n",
    "# Assuming the filenames are the same across directories, get the list from one directory\n",
    "common_files = sorted([f for f in os.listdir(prediction_dir) if f.endswith('.nii') or f.endswith('.nii.gz')])\n",
    "\n",
    "def apply_window(image, level=40, width=80):\n",
    "    lower = level - (width / 2)\n",
    "    upper = level + (width / 2)\n",
    "    return np.clip((image - lower) / (upper - lower), 0, 1)\n",
    "\n",
    "def plot_images(file_name, slice_idx):\n",
    "    # Construct file paths\n",
    "    prediction_file_path = os.path.join(prediction_dir, file_name)\n",
    "    ground_truth_file_path = os.path.join(ground_truth_dir, file_name)\n",
    "    ct_image_file_path = os.path.join(ct_images_dir, file_name)\n",
    "\n",
    "    # Load the files\n",
    "    prediction_img = nib.load(prediction_file_path)\n",
    "    ground_truth_img = nib.load(ground_truth_file_path)\n",
    "    ct_img = nib.load(ct_image_file_path)\n",
    "\n",
    "    # Convert the data to numpy arrays\n",
    "    prediction_data = prediction_img.get_fdata()\n",
    "    ground_truth_data = ground_truth_img.get_fdata()\n",
    "    ct_data = ct_img.get_fdata()\n",
    "\n",
    "    # Adjust slice_idx if it's out of bounds for any of the images\n",
    "    max_slices = min(prediction_data.shape[2], ground_truth_data.shape[2], ct_data.shape[2])\n",
    "    slice_idx = min(slice_idx, max_slices - 1)\n",
    "\n",
    "    # Apply custom windowing to the CT head image\n",
    "    ct_data_windowed = apply_window(ct_data)\n",
    "\n",
    "    # Plot the images\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(20, 5))\n",
    "    axes[0].imshow(ground_truth_data[:, :, slice_idx], cmap='gray')\n",
    "    axes[0].set_title('Ground Truth Image')\n",
    "    axes[1].imshow(prediction_data[:, :, slice_idx], cmap='gray')\n",
    "    axes[1].set_title('Prediction')\n",
    "    axes[2].imshow(ct_data_windowed[:, :, slice_idx], cmap='gray')\n",
    "    axes[2].imshow(ground_truth_data[:, :, slice_idx], cmap='hot', alpha=0.5)\n",
    "    axes[2].set_title('CT with Ground Truth Overlay')\n",
    "    plt.show()\n",
    "\n",
    "# Widget for file selection\n",
    "file_name_widget = Dropdown(options=common_files)\n",
    "slice_idx_widget = IntSlider(min=0, max=1, step=1, value=0)  # Initial max and value set to 0\n",
    "\n",
    "# Create an interactive plot\n",
    "plot = interactive(plot_images, file_name=file_name_widget, slice_idx=slice_idx_widget)\n",
    "\n",
    "# Update the maximum value and value of the slice index slider whenever a new file is selected\n",
    "def update_slice_idx_range(*args):\n",
    "    ct_img = nib.load(os.path.join(ct_images_dir, file_name_widget.value))\n",
    "    ct_data = ct_img.get_fdata()\n",
    "    slice_idx_widget.max = ct_data.shape[2] - 1\n",
    "    slice_idx_widget.value = min(slice_idx_widget.value, slice_idx_widget.max)\n",
    "\n",
    "file_name_widget.observe(update_slice_idx_range, 'value')\n",
    "\n",
    "# Manually call the update function to set the initial max value of the slice index slider\n",
    "update_slice_idx_range()\n",
    "\n",
    "# Display the interactive plot\n",
    "display(plot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interactive, IntSlider, Dropdown\n",
    "\n",
    "prediction_dir = r\"D:\\CTH_archive\\CTP_STRIPPED\"\n",
    "ground_truth_dir = r\"D:\\CTH_archive\\TMAX_NIFTI_QUANT_REGISTERED\"  # Updated path for ground truth images\n",
    "ct_images_dir = r\"D:\\CTH_archive\\CTH_NIFTI\"  # Directory for CT head images\n",
    "\n",
    "# Get the .nii.gz files in the directories\n",
    "prediction_files = sorted([f for f in os.listdir(prediction_dir) if f.endswith('.nii') or f.endswith('.nii.gz')])\n",
    "ground_truth_files = sorted([f for f in os.listdir(ground_truth_dir) if f.endswith('.nii') or f.endswith('.nii.gz')])\n",
    "ct_image_files = sorted([f for f in os.listdir(ct_images_dir) if f.endswith('.nii') or f.endswith('.nii.gz')])\n",
    "\n",
    "def apply_window(image, level=40, width=80):\n",
    "    lower = level - (width / 2)\n",
    "    upper = level + (width / 2)\n",
    "    return np.clip((image - lower) / (upper - lower), 0, 1)\n",
    "\n",
    "def plot_images(prediction_file, ground_truth_file, ct_image_file, slice_idx):\n",
    "    # Load the files\n",
    "    prediction_img = nib.load(os.path.join(prediction_dir, prediction_file))\n",
    "    ground_truth_img = nib.load(os.path.join(ground_truth_dir, ground_truth_file))\n",
    "    ct_img = nib.load(os.path.join(ct_images_dir, ct_image_file))\n",
    "\n",
    "    # Convert the data to numpy arrays\n",
    "    prediction_data = prediction_img.get_fdata()\n",
    "    ground_truth_data = ground_truth_img.get_fdata()\n",
    "    ct_data = ct_img.get_fdata()\n",
    "\n",
    "    # Apply custom windowing to the CT head image\n",
    "    ct_data_windowed = apply_window(ct_data)\n",
    "\n",
    "    # Plot the ground truth image, the prediction, the windowed CT head image, and the windowed CT with ground truth overlay\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(20, 5))\n",
    "    axes[0].imshow(ground_truth_data[:, :, slice_idx], cmap='gray')\n",
    "    axes[0].set_title('Ground Truth Image')\n",
    "    axes[1].imshow(prediction_data[:, :, slice_idx], cmap='gray')\n",
    "    axes[1].set_title('Prediction')\n",
    "    axes[2].imshow(ct_data_windowed[:, :, slice_idx], cmap='gray')  # Show the windowed CT head image again for overlay\n",
    "    axes[2].imshow(ground_truth_data[:, :, slice_idx], cmap='hot', alpha=0.5)  # Overlay the ground truth\n",
    "    axes[2].set_title('CT with Ground Truth Overlay')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Create widgets for file selection and slice index\n",
    "prediction_file_widget = Dropdown(options=prediction_files)\n",
    "ground_truth_file_widget = Dropdown(options=ground_truth_files)\n",
    "ct_image_file_widget = Dropdown(options=ct_image_files)\n",
    "slice_idx_widget = IntSlider(min=0, max=1, step=1, value=0)  # Initial max and value set to 0\n",
    "\n",
    "# Create an interactive plot\n",
    "plot = interactive(plot_images, prediction_file=prediction_file_widget, ground_truth_file=ground_truth_file_widget, ct_image_file=ct_image_file_widget, slice_idx=slice_idx_widget)\n",
    "\n",
    "# Update the maximum value and value of the slice index slider whenever a new CT image is selected\n",
    "def update_slice_idx_range(*args):\n",
    "    ct_img = nib.load(os.path.join(ct_images_dir, ct_image_file_widget.value))\n",
    "    ct_data = ct_img.get_fdata()\n",
    "    slice_idx_widget.max = ct_data.shape[2] - 1\n",
    "    slice_idx_widget.value = min(slice_idx_widget.value, slice_idx_widget.max)\n",
    "\n",
    "ct_image_file_widget.observe(update_slice_idx_range, 'value')\n",
    "\n",
    "# Manually call the update function to set the initial max value of the slice index slider\n",
    "update_slice_idx_range()\n",
    "\n",
    "# Display the interactive plot\n",
    "display(plot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import Dropdown, IntSlider, interactive\n",
    "\n",
    "# Base directory paths\n",
    "prediction_dir = r\"D:\\CTH_archive\\CTP_STRIPPED\"\n",
    "ground_truth_dir = r\"D:\\CTH_archive\\TMAX_NIFTI_QUANT\\REGISTERED_ADJUSTED\"\n",
    "ct_images_dir = r\"D:\\CTH_archive\\CTH_STRIPPED\"\n",
    "\n",
    "# Assuming all base filenames are the same across directories, we can just list files from one directory\n",
    "file_options = sorted([f for f in os.listdir(ct_images_dir) if f.endswith('.nii') or f.endswith('.nii.gz')])\n",
    "\n",
    "def apply_window(image, level=40, width=80):\n",
    "    lower = level - (width / 2)\n",
    "    upper = level + (width / 2)\n",
    "    return np.clip((image - lower) / (upper - lower), 0, 1)\n",
    "\n",
    "def plot_images(selected_file, slice_idx):\n",
    "    # Construct file paths for each type of image using the selected file\n",
    "    prediction_file_path = os.path.join(prediction_dir, selected_file)\n",
    "    ground_truth_file_path = os.path.join(ground_truth_dir, selected_file)\n",
    "    ct_image_file_path = os.path.join(ct_images_dir, selected_file)\n",
    "\n",
    "    # Load the files\n",
    "    prediction_img = nib.load(prediction_file_path)\n",
    "    ground_truth_img = nib.load(ground_truth_file_path)\n",
    "    ct_img = nib.load(ct_image_file_path)\n",
    "\n",
    "    # Convert the data to numpy arrays\n",
    "    prediction_data = prediction_img.get_fdata()\n",
    "    ground_truth_data = ground_truth_img.get_fdata()\n",
    "    ct_data = ct_img.get_fdata()\n",
    "\n",
    "    # Apply custom windowing to the CT head image\n",
    "    ct_data_windowed = apply_window(ct_data)\n",
    "\n",
    "    # Plot the images\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(20, 5))\n",
    "    axes[0].imshow(ground_truth_data[:, :, slice_idx], cmap='gray')\n",
    "    axes[1].imshow(prediction_data[:, :, slice_idx], cmap='gray')\n",
    "    axes[2].imshow(ct_data_windowed[:, :, slice_idx], cmap='gray')\n",
    "    axes[3].imshow(ct_data_windowed[:, :, slice_idx], cmap='gray')\n",
    "    axes[3].imshow(ground_truth_data[:, :, slice_idx], cmap='hot', alpha=0.5)\n",
    "    for ax in axes:\n",
    "        ax.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Create widgets for file selection and slice index\n",
    "file_widget = Dropdown(options=file_options)\n",
    "slice_idx_widget = IntSlider(min=0, max=1, step=1, value=0)\n",
    "\n",
    "# Create an interactive plot\n",
    "plot = interactive(plot_images, selected_file=file_widget, slice_idx=slice_idx_widget)\n",
    "\n",
    "# Update the maximum value and value of the slice index slider whenever a new file is selected\n",
    "def update_slice_idx_range(*args):\n",
    "    ct_img = nib.load(os.path.join(ct_images_dir, file_widget.value))\n",
    "    ct_data = ct_img.get_fdata()\n",
    "    slice_idx_widget.max = ct_data.shape[2] - 1\n",
    "    slice_idx_widget.value = min(slice_idx_widget.value, slice_idx_widget.max)\n",
    "\n",
    "file_widget.observe(update_slice_idx_range, 'value')\n",
    "\n",
    "# Manually call the update function to set the initial max value of the slice index slider\n",
    "update_slice_idx_range()\n",
    "\n",
    "# Display the interactive plot\n",
    "display(plot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_list = [x.split(' ')[0] for x in os.listdir('D:\\CTH_archive\\TMAX_NIFTI_QUANT\\REGISTERED')]\n",
    "preds_list = [x.replace('.nii', '') for x in preds_list]\n",
    "CTH_DICOM_SPLIT = [x.split(' ')[0] for x in os.listdir('D:\\CTH_archive\\CTH_DICOM')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_of_interest = set(CTH_DICOM_SPLIT) - set(preds_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_listing = os.listdir(\"D:\\CTH_archive\\CTH_DICOM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering process\n",
    "extracted_paths = []\n",
    "for file_name in directory_listing:\n",
    "    for name in names_of_interest:\n",
    "        if name in file_name:\n",
    "            extracted_paths.append(file_name)\n",
    "            break  # Stop the inner loop once a match is found\n",
    "\n",
    "# Display the extracted file paths\n",
    "for path in extracted_paths:\n",
    "    print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "base_directory = \"D:\\\\CTH_archive\\\\CTH_DICOM\"\n",
    "\n",
    "for path in extracted_paths:\n",
    "    # Construct the full path for the patient directory\n",
    "    patient_directory = os.path.join(base_directory, path)\n",
    "    \n",
    "    # Skip if the path is not a directory (e.g., it's a file like 'BILLIPS_JAMES.nii')\n",
    "    if not os.path.isdir(patient_directory):\n",
    "        continue\n",
    "\n",
    "    # Extract the patient name from the path\n",
    "    patient_name = path.split(' ')[0]  # Assuming patient name is the first part\n",
    "\n",
    "    # Find the last subdirectory within the patient directory, which represents the latest session or date\n",
    "    sessions = [d for d in os.listdir(patient_directory) if os.path.isdir(os.path.join(patient_directory, d))]\n",
    "    sessions.sort()  # Sort to ensure order, in case it's based on date or sequence\n",
    "    if not sessions:  # Check if the list is empty\n",
    "        continue  # Skip if there are no session directories\n",
    "    last_session = sessions[-1]  # Get the last session based on sorted order\n",
    "\n",
    "    # Construct the full path for the last session directory\n",
    "    session_directory = os.path.join(patient_directory, last_session)\n",
    "    \n",
    "    # Specify the output filename using the patient's name\n",
    "    output_file = os.path.join(\"D:\\\\CTH_archive\\\\NIfTI_TEST_SET\", f\"{patient_name}.nii\")\n",
    "    \n",
    "    # Ensure the output directory exists\n",
    "    os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "\n",
    "    # Call the convert_series_to_nifti function for the last session directory\n",
    "    convert_series_to_nifti(session_directory, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pydicom\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def load_dicom_series(directory):\n",
    "    dicom_files = [(os.path.join(directory, f), f) for f in os.listdir(directory) if f.endswith('.dcm')]\n",
    "    dicoms = [(pydicom.dcmread(path), file_name) for path, file_name in dicom_files]\n",
    "    dicoms.sort(key=lambda x: int(x[0].InstanceNumber))\n",
    "    return dicoms\n",
    "\n",
    "def display_image(image, file_name):\n",
    "    clear_output(wait=True)\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.title(file_name)  # Display the file name as the title\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def get_last_subdir(base_path):\n",
    "    # List all the entries in the base path\n",
    "    all_entries = os.listdir(base_path)\n",
    "    \n",
    "    # Filter out files, leaving only directories\n",
    "    dir_entries = [entry for entry in all_entries if os.path.isdir(os.path.join(base_path, entry))]\n",
    "    \n",
    "    # Sort the directories to get the last one\n",
    "    dir_entries.sort()\n",
    "    \n",
    "    # Return the full path of the last subdirectory if available, else return None\n",
    "    return os.path.join(base_path, dir_entries[-1]) if dir_entries else None\n",
    "\n",
    "# Example usage\n",
    "base_path = r\"D:\\CTH_archive\\CTH_DICOM\\TOUATI_MOHAMED 3117292\"\n",
    "dicom_series_directory = get_last_subdir(base_path)\n",
    "\n",
    "dicom_series = load_dicom_series(dicom_series_directory)\n",
    "\n",
    "slider = widgets.IntSlider(value=0, min=0, max=len(dicom_series)-1, step=1, description='Image Index:')\n",
    "\n",
    "def update_image(image_index):\n",
    "    dicom_data, file_name = dicom_series[image_index]\n",
    "    display_image(dicom_data.pixel_array, file_name)\n",
    "\n",
    "widgets.interactive(update_image, image_index=slider)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fx_bounding_box",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
